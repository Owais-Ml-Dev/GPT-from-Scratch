{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13698506,"sourceType":"datasetVersion","datasetId":8713607},{"sourceId":14073291,"sourceType":"datasetVersion","datasetId":8958381},{"sourceId":14077432,"sourceType":"datasetVersion","datasetId":8961420}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM - VOID","metadata":{}},{"cell_type":"markdown","source":"# 1. Setup & Dependencies","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"_uuid":"b9b582a7-9957-44dc-bd02-440d5780f56f","_cell_guid":"fc7cf057-c82d-4bd1-9cd6-7053cecf5ce4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:33.217375Z","iopub.execute_input":"2025-12-10T13:41:33.218093Z","iopub.status.idle":"2025-12-10T13:41:37.975300Z","shell.execute_reply.started":"2025-12-10T13:41:33.218066Z","shell.execute_reply":"2025-12-10T13:41:37.974475Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport tiktoken\nimport matplotlib.pyplot as plt\nimport urllib.request","metadata":{"_uuid":"3ccf592d-741e-467b-a232-0a9775ba5877","_cell_guid":"dc0e13e0-0ebe-4a28-b00b-d2abc09282e9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:37.976574Z","iopub.execute_input":"2025-12-10T13:41:37.976796Z","iopub.status.idle":"2025-12-10T13:41:41.818267Z","shell.execute_reply.started":"2025-12-10T13:41:37.976774Z","shell.execute_reply":"2025-12-10T13:41:41.817636Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# 2. GPT Architecture Components","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Multi-Head Self-Attention","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        assert (d_out % num_heads == 0), \\\n            \"d_out must be divisible by num_heads\"\n\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\n            \"mask\",\n            torch.triu(torch.ones(context_length, context_length),\n                       diagonal=1)\n        )\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape\n\n        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        # We implicitly split the matrix by adding a `num_heads` dimension\n        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n\n        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n        keys = keys.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n\n        # Original mask truncated to the number of tokens and converted to boolean\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n\n        # Use the mask to fill attention scores\n        attn_scores.masked_fill_(mask_bool, -torch.inf)\n        \n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        # Shape: (b, num_tokens, num_heads, head_dim)\n        context_vec = (attn_weights @ values).transpose(1, 2) \n        \n        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec) # optional projection\n\n        return context_vec","metadata":{"_uuid":"73ca57e5-307c-489d-a991-fb873b3abd7d","_cell_guid":"3955071d-ad0d-4ff7-b8a9-0601c2cfe67b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:41.819067Z","iopub.execute_input":"2025-12-10T13:41:41.819417Z","iopub.status.idle":"2025-12-10T13:41:41.827534Z","shell.execute_reply.started":"2025-12-10T13:41:41.819389Z","shell.execute_reply":"2025-12-10T13:41:41.826776Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 2.2 Layer Normalization","metadata":{}},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, emb_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n        return self.scale * norm_x + self.shift\n","metadata":{"_uuid":"9d228853-cf56-4a37-acf4-01f54f3bfa0d","_cell_guid":"2199aa4a-e373-4ba8-8b9a-8c9443b12c5d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:41.829087Z","iopub.execute_input":"2025-12-10T13:41:41.829301Z","iopub.status.idle":"2025-12-10T13:41:41.850627Z","shell.execute_reply.started":"2025-12-10T13:41:41.829265Z","shell.execute_reply":"2025-12-10T13:41:41.849962Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 2.3 GELU Activation","metadata":{}},{"cell_type":"code","source":"class GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n            (x + 0.044715 * torch.pow(x, 3))\n        ))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:13:13.525505Z","iopub.execute_input":"2025-12-10T15:13:13.525782Z","iopub.status.idle":"2025-12-10T15:13:13.530255Z","shell.execute_reply.started":"2025-12-10T15:13:13.525761Z","shell.execute_reply":"2025-12-10T15:13:13.529657Z"}},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":"## 2.4 Feedforward Network","metadata":{}},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n            GELU(), ## Activation\n            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n        )\n\n    def forward(self, x):\n        return self.layers(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:13:14.572880Z","iopub.execute_input":"2025-12-10T15:13:14.573569Z","iopub.status.idle":"2025-12-10T15:13:14.577775Z","shell.execute_reply.started":"2025-12-10T15:13:14.573544Z","shell.execute_reply":"2025-12-10T15:13:14.576928Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"## 2.5 Transformer Block","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = MultiHeadAttention(\n            d_in=cfg[\"emb_dim\"],\n            d_out=cfg[\"emb_dim\"],\n            context_length=cfg[\"context_length\"],\n            num_heads=cfg[\"n_heads\"], \n            dropout=cfg[\"drop_rate\"],\n            qkv_bias=cfg[\"qkv_bias\"])\n        self.ff = FeedForward(cfg)\n        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x):\n        # Shortcut connection for attention block\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        # Shortcut connection for feed forward block\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        # 2*4*768\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        return x","metadata":{"_uuid":"f0e593d8-2943-437b-b341-9e8e0000f470","_cell_guid":"1069cb7b-01df-4308-b7d1-6689311f1896","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:41.851320Z","iopub.execute_input":"2025-12-10T13:41:41.851659Z","iopub.status.idle":"2025-12-10T13:41:41.866338Z","shell.execute_reply.started":"2025-12-10T13:41:41.851616Z","shell.execute_reply":"2025-12-10T13:41:41.865618Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 2.6 GPT Model Definition","metadata":{}},{"cell_type":"code","source":"class GPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n        \n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n        \n        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(\n            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n        )\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_emb(x)\n        x = self.trf_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits","metadata":{"_uuid":"7c55ea3f-a96c-4639-8c40-a7621f618d06","_cell_guid":"2b72e9a2-e1d1-46b2-bffd-24fb8ff1eb07","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:41.866957Z","iopub.execute_input":"2025-12-10T13:41:41.867518Z","iopub.status.idle":"2025-12-10T13:41:41.884869Z","shell.execute_reply.started":"2025-12-10T13:41:41.867476Z","shell.execute_reply":"2025-12-10T13:41:41.884180Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 2.7 Base Configuration & Parameter Count","metadata":{}},{"cell_type":"code","source":"GPT_CONFIG = {\n    \"vocab_size\": 50257,   # Vocabulary size\n    \"context_length\": 1024,\n    \"emb_dim\": 768,        # Embedding dimension\n    \"n_heads\": 12,         # Number of attention heads\n    \"n_layers\": 12,        # Number of layers\n    \"drop_rate\":0.15,      # Dropout rate\n    \"qkv_bias\": True      # Query-key-value bias\n}","metadata":{"_uuid":"7ec051de-5bce-47bf-a65a-45ab2e864138","_cell_guid":"8d4c2f80-ec63-4f40-89de-56a30d6e373d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:41.885643Z","iopub.execute_input":"2025-12-10T13:41:41.885875Z","iopub.status.idle":"2025-12-10T13:41:41.904485Z","shell.execute_reply.started":"2025-12-10T13:41:41.885860Z","shell.execute_reply":"2025-12-10T13:41:41.903886Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = GPTModel(GPT_CONFIG)\nnum_params = sum(p.numel() for p in model.parameters())\nprint(\"Total number of parameters:\", num_params)","metadata":{"_uuid":"a055566d-b5f5-451b-b6b0-902d39e6faf1","_cell_guid":"31102220-184b-4524-aea5-ff722f9b9fee","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:41.905040Z","iopub.execute_input":"2025-12-10T13:41:41.905269Z","iopub.status.idle":"2025-12-10T13:41:43.277645Z","shell.execute_reply.started":"2025-12-10T13:41:41.905245Z","shell.execute_reply":"2025-12-10T13:41:43.277026Z"}},"outputs":[{"name":"stdout","text":"Total number of parameters: 163037184\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# 3. Load Pretrained GPT-2 Weights","metadata":{}},{"cell_type":"code","source":"pip install tensorflow>=2.15.0 tqdm>=4.66","metadata":{"_uuid":"71390ce7-fd2c-4cf4-ae12-98298f87f0bd","_cell_guid":"c505679a-0b39-431e-9f07-3bbc3fe3cdeb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:43.278334Z","iopub.execute_input":"2025-12-10T13:41:43.278546Z","iopub.status.idle":"2025-12-10T13:41:47.475295Z","shell.execute_reply.started":"2025-12-10T13:41:43.278521Z","shell.execute_reply":"2025-12-10T13:41:47.474503Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nimport tqdm\n\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"tqdm version:\", tqdm.__version__)","metadata":{"_uuid":"4f0def32-3c34-49cb-98fe-a7bffac589ec","_cell_guid":"e1d3ae54-be60-44a3-9ee7-fcca9b177f9f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:41:47.478154Z","iopub.execute_input":"2025-12-10T13:41:47.478424Z","iopub.status.idle":"2025-12-10T13:42:03.993756Z","shell.execute_reply.started":"2025-12-10T13:41:47.478400Z","shell.execute_reply":"2025-12-10T13:42:03.993097Z"}},"outputs":[{"name":"stderr","text":"2025-12-10 13:41:49.097902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765374109.315059      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765374109.376472      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow version: 2.18.0\ntqdm version: 4.67.1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 3.1 Import GPT-2 Download Helper","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/gpt-download3-py')","metadata":{"_uuid":"41e3afbe-f2aa-48c4-b934-4fcb14223e3c","_cell_guid":"67b604bc-4f15-453f-9918-d05ffa92b744","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:03.994437Z","iopub.execute_input":"2025-12-10T13:42:03.994911Z","iopub.status.idle":"2025-12-10T13:42:03.998727Z","shell.execute_reply.started":"2025-12-10T13:42:03.994891Z","shell.execute_reply":"2025-12-10T13:42:03.997931Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from gpt_download3 import download_and_load_gpt2","metadata":{"_uuid":"1cc95f9b-2fe3-43f1-a11f-d55a7ba5b691","_cell_guid":"e3566dea-ae02-4c07-8c54-5984a4791076","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:03.999975Z","iopub.execute_input":"2025-12-10T13:42:04.000344Z","iopub.status.idle":"2025-12-10T13:42:04.032723Z","shell.execute_reply.started":"2025-12-10T13:42:04.000316Z","shell.execute_reply":"2025-12-10T13:42:04.032030Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")","metadata":{"_uuid":"4e4c7225-beca-483d-9014-bbd68934a09a","_cell_guid":"bc26a5e7-220a-41e6-bbb3-d8b02a944ff4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:04.033455Z","iopub.execute_input":"2025-12-10T13:42:04.033691Z","iopub.status.idle":"2025-12-10T13:42:23.294083Z","shell.execute_reply.started":"2025-12-10T13:42:04.033677Z","shell.execute_reply":"2025-12-10T13:42:23.293483Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\ncheckpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 146kiB/s]\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\nencoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 7.98MiB/s]\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\nhparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 197kiB/s]\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\nmodel.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:17<00:00, 28.3MiB/s] \n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\nmodel.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 14.6MiB/s]\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\nmodel.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 3.97MiB/s]\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\nvocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 3.86MiB/s]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"Settings:\", settings)\nprint(\"Parameter dictionary keys:\", params.keys())","metadata":{"_uuid":"08f12e6d-fcef-4992-851d-39dcb181a50f","_cell_guid":"3c31651c-3c17-46f8-a14b-a7abd9be9a97","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:23.294868Z","iopub.execute_input":"2025-12-10T13:42:23.295124Z","iopub.status.idle":"2025-12-10T13:42:23.299626Z","shell.execute_reply.started":"2025-12-10T13:42:23.295099Z","shell.execute_reply":"2025-12-10T13:42:23.298925Z"}},"outputs":[{"name":"stdout","text":"Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\nParameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 3.2 Model Configurations","metadata":{}},{"cell_type":"code","source":"from gpt_download3 import download_and_load_gpt2\n\nBASE_CONFIG = {\n    \"vocab_size\": 50257,     # Vocabulary size\n    \"context_length\": 1024,  # Context length\n    \"drop_rate\": 0.15,        # Dropout rate\n    \"qkv_bias\": True         # Query-key-value bias\n}\n\nmodel_configs = {\n    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n}\n\nCHOOSE_MODEL = \"gpt2-small (124M)\"\n\nBASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n\nmodel_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\nsettings, params = download_and_load_gpt2(\n    model_size=model_size,\n    models_dir=\"gpt2\"\n)","metadata":{"_uuid":"dc47e8d1-d0f4-4028-a637-6475413950a8","_cell_guid":"b7979e31-43c7-4c0f-8847-3cfd2eae31be","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:23.300719Z","iopub.execute_input":"2025-12-10T13:42:23.301015Z","iopub.status.idle":"2025-12-10T13:42:24.695952Z","shell.execute_reply.started":"2025-12-10T13:42:23.300991Z","shell.execute_reply":"2025-12-10T13:42:24.695332Z"}},"outputs":[{"name":"stdout","text":"File already exists and is up-to-date: gpt2/124M/checkpoint\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"File already exists and is up-to-date: gpt2/124M/encoder.json\nFile already exists and is up-to-date: gpt2/124M/hparams.json\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\nFile already exists and is up-to-date: gpt2/124M/model.ckpt.index\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\nFile already exists and is up-to-date: gpt2/124M/vocab.bpe\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 3.3 Sanity Check Config Match","metadata":{}},{"cell_type":"code","source":"print(settings[\"n_vocab\"] == BASE_CONFIG[\"vocab_size\"])      # True or False\nprint(settings[\"n_ctx\"] == BASE_CONFIG[\"context_length\"])     # True or False\nprint(settings[\"n_embd\"] == BASE_CONFIG[\"emb_dim\"])           # True or False\nprint(settings[\"n_head\"] == BASE_CONFIG[\"n_heads\"])           # True or False\nprint(settings[\"n_layer\"] == BASE_CONFIG[\"n_layers\"])         # True or False","metadata":{"_uuid":"17db244d-2bb8-4340-bf78-f919060f1ecf","_cell_guid":"851f673b-90d5-43c9-b6f6-2a8a836e2462","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:24.696776Z","iopub.execute_input":"2025-12-10T13:42:24.697091Z","iopub.status.idle":"2025-12-10T13:42:24.701751Z","shell.execute_reply.started":"2025-12-10T13:42:24.697072Z","shell.execute_reply":"2025-12-10T13:42:24.700925Z"}},"outputs":[{"name":"stdout","text":"True\nTrue\nTrue\nTrue\nTrue\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## 3.4 Weight Assignment Helper","metadata":{}},{"cell_type":"code","source":"def assign(left, right):\n    if left.shape != right.shape:\n        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n    return torch.nn.Parameter(torch.tensor(right))","metadata":{"_uuid":"ee30c943-10f0-46b1-b8bb-bdb2e07dbf57","_cell_guid":"9243a75a-9281-48ef-91f9-e6c5d70c4e5e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:24.702542Z","iopub.execute_input":"2025-12-10T13:42:24.703504Z","iopub.status.idle":"2025-12-10T13:42:24.716560Z","shell.execute_reply.started":"2025-12-10T13:42:24.703484Z","shell.execute_reply":"2025-12-10T13:42:24.715839Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## 3.5 Load Weights into Custom GPT","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef load_weights_into_gpt(gpt, params):\n    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n    \n    for b in range(len(params[\"blocks\"])):\n        q_w, k_w, v_w = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.weight = assign(\n            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n        gpt.trf_blocks[b].att.W_key.weight = assign(\n            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n        gpt.trf_blocks[b].att.W_value.weight = assign(\n            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n\n        q_b, k_b, v_b = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.bias = assign(\n            gpt.trf_blocks[b].att.W_query.bias, q_b)\n        gpt.trf_blocks[b].att.W_key.bias = assign(\n            gpt.trf_blocks[b].att.W_key.bias, k_b)\n        gpt.trf_blocks[b].att.W_value.bias = assign(\n            gpt.trf_blocks[b].att.W_value.bias, v_b)\n\n        gpt.trf_blocks[b].att.out_proj.weight = assign(\n            gpt.trf_blocks[b].att.out_proj.weight, \n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].att.out_proj.bias = assign(\n            gpt.trf_blocks[b].att.out_proj.bias, \n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n\n        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n            gpt.trf_blocks[b].ff.layers[0].weight, \n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n            gpt.trf_blocks[b].ff.layers[0].bias, \n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n            gpt.trf_blocks[b].ff.layers[2].weight, \n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n            gpt.trf_blocks[b].ff.layers[2].bias, \n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n\n        gpt.trf_blocks[b].norm1.scale = assign(\n            gpt.trf_blocks[b].norm1.scale, \n            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n        gpt.trf_blocks[b].norm1.shift = assign(\n            gpt.trf_blocks[b].norm1.shift, \n            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n        gpt.trf_blocks[b].norm2.scale = assign(\n            gpt.trf_blocks[b].norm2.scale, \n            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n        gpt.trf_blocks[b].norm2.shift = assign(\n            gpt.trf_blocks[b].norm2.shift, \n            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n\n    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])","metadata":{"_uuid":"d84c9677-320a-47ea-be8b-165e42a652c0","_cell_guid":"bcf34f9e-7d0b-4943-a329-6b61041da8d6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:24.717273Z","iopub.execute_input":"2025-12-10T13:42:24.717525Z","iopub.status.idle":"2025-12-10T13:42:24.732277Z","shell.execute_reply.started":"2025-12-10T13:42:24.717503Z","shell.execute_reply":"2025-12-10T13:42:24.731746Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## 3.6 Instantiate Model & Move to Device","metadata":{}},{"cell_type":"code","source":"model = GPTModel(BASE_CONFIG)\nload_weights_into_gpt(model, params)","metadata":{"_uuid":"8655925e-0f74-4047-b12c-aa074d5e3571","_cell_guid":"73b2aa1d-b763-4ec1-a76f-b9c11454efde","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:24.733085Z","iopub.execute_input":"2025-12-10T13:42:24.733409Z","iopub.status.idle":"2025-12-10T13:42:26.261720Z","shell.execute_reply.started":"2025-12-10T13:42:24.733382Z","shell.execute_reply":"2025-12-10T13:42:26.260902Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"_uuid":"ee1c135b-e247-4771-9b13-8a12a2937012","_cell_guid":"9715c54f-1040-4816-94f8-4a4a9e46ab2f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:26.262563Z","iopub.execute_input":"2025-12-10T13:42:26.262775Z","iopub.status.idle":"2025-12-10T13:42:26.347540Z","shell.execute_reply.started":"2025-12-10T13:42:26.262759Z","shell.execute_reply":"2025-12-10T13:42:26.346811Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model.to(device)","metadata":{"_uuid":"8eb23a0f-71f9-41aa-b6c8-15e5f7d904ce","_cell_guid":"4da54465-740e-4c27-938a-b1f81a40bd30","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:26.348259Z","iopub.execute_input":"2025-12-10T13:42:26.348532Z","iopub.status.idle":"2025-12-10T13:42:26.742315Z","shell.execute_reply.started":"2025-12-10T13:42:26.348508Z","shell.execute_reply":"2025-12-10T13:42:26.741679Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.15, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.15, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.15, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(next(model.parameters()).device)        # should be your device\nprint(model.pos_emb.weight.shape, params[\"wpe\"].shape)\nprint(model.tok_emb.weight.shape, params[\"wte\"].shape)\nprint(len(params[\"blocks\"]), len(model.trf_blocks))","metadata":{"_uuid":"a3cb57bb-a2b1-498d-a5af-fa743932b8f8","_cell_guid":"93f20349-2677-4a40-bcda-f5272aae8cac","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:26.743041Z","iopub.execute_input":"2025-12-10T13:42:26.743232Z","iopub.status.idle":"2025-12-10T13:42:26.748100Z","shell.execute_reply.started":"2025-12-10T13:42:26.743211Z","shell.execute_reply":"2025-12-10T13:42:26.747403Z"}},"outputs":[{"name":"stdout","text":"cuda:0\ntorch.Size([1024, 768]) (1024, 768)\ntorch.Size([50257, 768]) (50257, 768)\n12 12\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## 3.7 Check Maximum Differences (Verification)","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef max_diff(t, arr):\n    arr_t = torch.tensor(arr, dtype=t.dtype, device=t.device)\n    return (t.detach() - arr_t).abs().max().item()\n\nprint(\"pos_emb max diff:\", max_diff(model.pos_emb.weight, params[\"wpe\"]))\nprint(\"tok_emb max diff:\", max_diff(model.tok_emb.weight, params[\"wte\"]))\nprint(\"out_head max diff:\", max_diff(model.out_head.weight, params[\"wte\"]))","metadata":{"_uuid":"73e1492d-30ea-40cf-a78c-30ecbce00dc0","_cell_guid":"708fd179-5432-4312-b234-8d1771c3b9e9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:26.749588Z","iopub.execute_input":"2025-12-10T13:42:26.749790Z","iopub.status.idle":"2025-12-10T13:42:26.902278Z","shell.execute_reply.started":"2025-12-10T13:42:26.749776Z","shell.execute_reply":"2025-12-10T13:42:26.901695Z"}},"outputs":[{"name":"stdout","text":"pos_emb max diff: 0.0\ntok_emb max diff: 0.0\nout_head max diff: 0.0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"b = 0  # first block\nq_w, k_w, v_w = np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n\nprint(\"block0 Q max diff:\", max_diff(model.trf_blocks[b].att.W_query.weight, q_w.T))\nprint(\"block0 K max diff:\", max_diff(model.trf_blocks[b].att.W_key.weight,   k_w.T))\nprint(\"block0 V max diff:\", max_diff(model.trf_blocks[b].att.W_value.weight, v_w.T))","metadata":{"_uuid":"0ec3c66b-f6cd-42d3-bce5-25f404bfe7b8","_cell_guid":"0d37bdf2-4054-4e8a-802f-eebe3310aff9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:26.902977Z","iopub.execute_input":"2025-12-10T13:42:26.903316Z","iopub.status.idle":"2025-12-10T13:42:26.932244Z","shell.execute_reply.started":"2025-12-10T13:42:26.903299Z","shell.execute_reply":"2025-12-10T13:42:26.931678Z"}},"outputs":[{"name":"stdout","text":"block0 Q max diff: 0.0\nblock0 K max diff: 0.0\nblock0 V max diff: 0.0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# 4. Text Generation Utilities (Pre-Finetuning Sanity Check)","metadata":{}},{"cell_type":"code","source":"def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n\n    # For-loop is the same as before: Get logits, and only focus on last time step\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n        logits = logits[:, -1, :]\n\n        # New: Filter logits with top_k sampling\n        if top_k is not None:\n            # Keep only top_k values\n            top_logits, _ = torch.topk(logits, top_k)\n            min_val = top_logits[:, -1]\n            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n\n        # New: Apply temperature scaling\n        if temperature > 0.0:\n            logits = logits / temperature\n\n            # Apply softmax to get probabilities\n            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n\n            # Sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n\n        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n        else:\n            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n\n        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n            break\n\n        # Same as before: append sampled index to the running sequence\n        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n\n    return idx\n\nimport tiktoken","metadata":{"_uuid":"477eed2a-4634-4cfe-857f-24b62da2160a","_cell_guid":"e3874d21-1e33-4c26-86a4-10b54595d776","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T15:20:10.281248Z","iopub.execute_input":"2025-12-10T15:20:10.281844Z","iopub.status.idle":"2025-12-10T15:20:10.288401Z","shell.execute_reply.started":"2025-12-10T15:20:10.281817Z","shell.execute_reply":"2025-12-10T15:20:10.287722Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"## 4.1 Tokenizer Helpers","metadata":{}},{"cell_type":"code","source":"def text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n    return encoded_tensor\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0) # remove batch dimension\n    return tokenizer.decode(flat.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:20:24.308147Z","iopub.execute_input":"2025-12-10T15:20:24.308845Z","iopub.status.idle":"2025-12-10T15:20:24.313114Z","shell.execute_reply.started":"2025-12-10T15:20:24.308819Z","shell.execute_reply":"2025-12-10T15:20:24.312274Z"}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"## 4.2 Quick Generation Test","metadata":{}},{"cell_type":"code","source":"tokenizer = tiktoken.get_encoding(\"gpt2\")\n\ntorch.manual_seed(123)\n\ntoken_ids = generate(\n    model=model,\n    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n    max_new_tokens=25,\n    context_size=BASE_CONFIG[\"context_length\"],\n    top_k=50,\n    temperature=1.5\n)\n\nprint(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T15:20:32.964926Z","iopub.execute_input":"2025-12-10T15:20:32.965442Z","iopub.status.idle":"2025-12-10T15:20:33.343750Z","shell.execute_reply.started":"2025-12-10T15:20:32.965418Z","shell.execute_reply":"2025-12-10T15:20:33.343061Z"}},"outputs":[{"name":"stdout","text":"Output text:\n Every effort moves you as a result.\n\n### Instruction:\nReply in a way that sounds like genuine, everyday conversation.\n\n###\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"# 5. Instruction Dataset Loading & Formatting","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Load JSON Dataset","metadata":{}},{"cell_type":"code","source":"import json\n\n# Import the JSON file\nwith open('/kaggle/input/training-dataset-json/training_dataset.json', 'r') as f:\n    data = json.load(f)\n\n# Print number of entries\nprint(f\"Total number of entries: {len(data)}\")","metadata":{"_uuid":"ad3980ff-e5be-4c20-be20-23b0c2781d39","_cell_guid":"e537bad0-fb9d-4d16-9af8-94919c816940","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:28.830883Z","iopub.execute_input":"2025-12-10T13:42:28.831178Z","iopub.status.idle":"2025-12-10T13:42:29.213518Z","shell.execute_reply.started":"2025-12-10T13:42:28.831161Z","shell.execute_reply":"2025-12-10T13:42:29.212680Z"}},"outputs":[{"name":"stdout","text":"Total number of entries: 40000\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# # Assuming 'data' is a list or similar iterable containing all your entries\n# desired_size = 25000\n\n# # If your dataset is larger than desired_size, keep first 20,000 entries\n# if len(data) > desired_size:\n#     data = data[:desired_size]\n#     print(f\"Data truncated to {desired_size} entries.\")\n# else:\n#     print(f\"Data size {len(data)} is less than {desired_size}, no truncation needed.\")","metadata":{"_uuid":"4e1edd82-7206-490e-b78c-c758fa8ffe6c","_cell_guid":"cfdbdf67-953f-44e4-943c-62bf88b68bc8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.214476Z","iopub.execute_input":"2025-12-10T13:42:29.215072Z","iopub.status.idle":"2025-12-10T13:42:29.218444Z","shell.execute_reply.started":"2025-12-10T13:42:29.215046Z","shell.execute_reply":"2025-12-10T13:42:29.217678Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"print(\"Example entry:\\n\", data[50])","metadata":{"_uuid":"a5cd378a-ea84-4030-b01f-c437da85672b","_cell_guid":"20d0ac37-116e-4f48-a59f-06fc5fd3b1c2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.222636Z","iopub.execute_input":"2025-12-10T13:42:29.222982Z","iopub.status.idle":"2025-12-10T13:42:29.236319Z","shell.execute_reply.started":"2025-12-10T13:42:29.222965Z","shell.execute_reply":"2025-12-10T13:42:29.235584Z"}},"outputs":[{"name":"stdout","text":"Example entry:\n {'instruction': 'Respond naturally, as if talking to someone you know and like.', 'input': 'Did your meeting go well?', 'output': 'Yeah, it went well! Everyone was on the same page, which is always nice.'}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"print(\"Another example entry:\\n\", data[999])","metadata":{"_uuid":"2433ec71-1325-4a35-897d-6730e79ab1c4","_cell_guid":"87a32830-bb0a-4f27-b9d0-3f7e8bd42c62","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.237042Z","iopub.execute_input":"2025-12-10T13:42:29.237318Z","iopub.status.idle":"2025-12-10T13:42:29.249943Z","shell.execute_reply.started":"2025-12-10T13:42:29.237282Z","shell.execute_reply":"2025-12-10T13:42:29.249247Z"}},"outputs":[{"name":"stdout","text":"Another example entry:\n {'instruction': \"Respond in a manner that's genuine, casual, and easy to understand.\", 'input': 'Do you call your parents often?', 'output': 'I try to call them at least once a week, maybe more. How often do you?'}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## 5.2 Prompt Formatting","metadata":{}},{"cell_type":"code","source":"def format_input(entry):\n    instruction_text = (\n        f\"Below is an instruction that describes a task. \"\n        f\"Write a response that appropriately completes the request.\"\n        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n    )\n\n    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n\n    return instruction_text + input_text","metadata":{"_uuid":"1f0fd9ba-cf45-4bee-98e8-05e638f9f349","_cell_guid":"9144eef9-b796-45a8-a857-58caf92c7d66","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.250694Z","iopub.execute_input":"2025-12-10T13:42:29.250881Z","iopub.status.idle":"2025-12-10T13:42:29.263220Z","shell.execute_reply.started":"2025-12-10T13:42:29.250859Z","shell.execute_reply":"2025-12-10T13:42:29.262675Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"model_input = format_input(data[44])\ndesired_response = f\"\\n\\n### Response:\\n{data[44]['output']}\"\n\nprint(model_input + desired_response)","metadata":{"_uuid":"f01528aa-a33c-4a88-8e38-0915ccd0f0cc","_cell_guid":"7a3a6d94-ab4b-4d40-bade-e856f752619a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.263958Z","iopub.execute_input":"2025-12-10T13:42:29.264151Z","iopub.status.idle":"2025-12-10T13:42:29.277818Z","shell.execute_reply.started":"2025-12-10T13:42:29.264136Z","shell.execute_reply":"2025-12-10T13:42:29.277119Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nRespond with a friendly tone that matches normal everyday conversation.\n\n### Input:\nThe humidity is unbearable right now.\n\n### Response:\nOh man, tell me about it! It's been hard to cool down even at night.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## 5.3 Train/Val/Test Split","metadata":{}},{"cell_type":"code","source":"train_portion = int(len(data) * 0.85)  # 85% for training\ntest_portion = int(len(data) * 0.1)    # 10% for testing\nval_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n\ntrain_data = data[:train_portion]\ntest_data = data[train_portion:train_portion + test_portion]\nval_data = data[train_portion + test_portion:]","metadata":{"_uuid":"23c694d0-9003-4fef-bd64-ab9bf6800728","_cell_guid":"7ce12b77-0df7-4e6c-bf7f-fcb25bc9ce69","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.278652Z","iopub.execute_input":"2025-12-10T13:42:29.278890Z","iopub.status.idle":"2025-12-10T13:42:29.291956Z","shell.execute_reply.started":"2025-12-10T13:42:29.278875Z","shell.execute_reply":"2025-12-10T13:42:29.291327Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"print(\"Training set length:\", len(train_data))\nprint(\"Validation set length:\", len(val_data))\nprint(\"Test set length:\", len(test_data))","metadata":{"_uuid":"312489cb-1be4-4735-8dc3-8522e85707a1","_cell_guid":"29f2a0f2-9a9c-4c17-816e-cf73e0bb2eb1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.292676Z","iopub.execute_input":"2025-12-10T13:42:29.292973Z","iopub.status.idle":"2025-12-10T13:42:29.305522Z","shell.execute_reply.started":"2025-12-10T13:42:29.292957Z","shell.execute_reply":"2025-12-10T13:42:29.304848Z"}},"outputs":[{"name":"stdout","text":"Training set length: 34000\nValidation set length: 2000\nTest set length: 4000\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# 6. PyTorch Dataset & Dataloaders","metadata":{}},{"cell_type":"markdown","source":"## 6.1 InstructionDataset","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\n\nclass InstructionDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n\n        # Pre-tokenize texts\n        self.encoded_texts = []\n        for entry in data:\n            instruction_plus_input = format_input(entry)\n            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n            full_text = instruction_plus_input + response_text\n            self.encoded_texts.append(\n                tokenizer.encode(full_text)\n            )\n\n    def __getitem__(self, index):\n        return self.encoded_texts[index]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"_uuid":"08cf5057-08e7-4494-b73e-2403cf00792a","_cell_guid":"d3612dab-834c-453e-a645-8f6e57fa9fe2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.306248Z","iopub.execute_input":"2025-12-10T13:42:29.306504Z","iopub.status.idle":"2025-12-10T13:42:29.319146Z","shell.execute_reply.started":"2025-12-10T13:42:29.306484Z","shell.execute_reply":"2025-12-10T13:42:29.318545Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## 6.2 Custom Collate Function","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(\n    batch,\n    pad_token_id=50256,\n    ignore_index=-100,\n    allowed_max_length=None,\n    device=\"cpu\"\n):\n    # Find the longest sequence in the batch\n    batch_max_length = max(len(item)+1 for item in batch)\n\n    # Pad and prepare inputs and targets\n    inputs_lst, targets_lst = [], []\n\n    for item in batch:\n        new_item = item.copy()\n        # Add an <|endoftext|> token\n        new_item += [pad_token_id]\n        # Pad sequences to max_length\n        padded = (\n            new_item + [pad_token_id] *\n            (batch_max_length - len(new_item))\n        )\n        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n\n        # New: Replace all but the first padding tokens in targets by ignore_index\n        mask = targets == pad_token_id\n        indices = torch.nonzero(mask).squeeze()\n        if indices.numel() > 1:\n            targets[indices[1:]] = ignore_index\n\n        # New: Optionally truncate to maximum sequence length\n        if allowed_max_length is not None:\n            inputs = inputs[:allowed_max_length]\n            targets = targets[:allowed_max_length]\n\n        inputs_lst.append(inputs)\n        targets_lst.append(targets)\n\n    # Convert list of inputs and targets to tensors and transfer to target device\n    inputs_tensor = torch.stack(inputs_lst).to(device)\n    targets_tensor = torch.stack(targets_lst).to(device)\n\n    return inputs_tensor, targets_tensor","metadata":{"_uuid":"c5b652e5-eebd-45f7-bd45-9272fdb271f6","_cell_guid":"7f5ec93e-4777-48ad-98f1-5393f0d3d290","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.319936Z","iopub.execute_input":"2025-12-10T13:42:29.320276Z","iopub.status.idle":"2025-12-10T13:42:29.337179Z","shell.execute_reply.started":"2025-12-10T13:42:29.320258Z","shell.execute_reply":"2025-12-10T13:42:29.336500Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from functools import partial\ncustomized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=256)","metadata":{"_uuid":"e64da595-ca0d-4c01-bf23-b4159527499a","_cell_guid":"15efb2db-180a-4250-9f6b-e6953deae59d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.338080Z","iopub.execute_input":"2025-12-10T13:42:29.338402Z","iopub.status.idle":"2025-12-10T13:42:29.353888Z","shell.execute_reply.started":"2025-12-10T13:42:29.338378Z","shell.execute_reply":"2025-12-10T13:42:29.353329Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"## 6.3 Dataloaders","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n\nnum_workers = 0\nbatch_size = 4\n\ntorch.manual_seed(123)\n\ntrain_dataset = InstructionDataset(train_data, tokenizer)\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    collate_fn=customized_collate_fn,\n    shuffle=True,\n    drop_last=True,\n    num_workers=num_workers\n)\n\nval_dataset = InstructionDataset(val_data, tokenizer)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    collate_fn=customized_collate_fn,\n    shuffle=False,\n    drop_last=False,\n    num_workers=num_workers\n)\n\ntest_dataset = InstructionDataset(test_data, tokenizer)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    collate_fn=customized_collate_fn,\n    shuffle=False,\n    drop_last=False,\n    num_workers=num_workers\n)","metadata":{"_uuid":"80e8960b-7c1d-4c15-b813-9ca26257662b","_cell_guid":"4728a3e9-b734-4abe-a3f5-0c7a3dce4ea8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:29.354629Z","iopub.execute_input":"2025-12-10T13:42:29.354896Z","iopub.status.idle":"2025-12-10T13:42:31.698505Z","shell.execute_reply.started":"2025-12-10T13:42:29.354875Z","shell.execute_reply":"2025-12-10T13:42:31.697685Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# print(\"Train loader:\")\n# for inputs, targets in train_loader:\n#     print(inputs.shape, targets.shape)","metadata":{"_uuid":"8548e2f0-4a8c-4893-a58e-3d223dfa6d44","_cell_guid":"a423ae6a-3449-461d-a63c-ea2b31fc6bf3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.699337Z","iopub.execute_input":"2025-12-10T13:42:31.699555Z","iopub.status.idle":"2025-12-10T13:42:31.702941Z","shell.execute_reply.started":"2025-12-10T13:42:31.699539Z","shell.execute_reply":"2025-12-10T13:42:31.702210Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"# 7. Training Utilities","metadata":{}},{"cell_type":"markdown","source":"## 7.1 Loss Calculation","metadata":{}},{"cell_type":"code","source":"def calc_loss_batch(input_batch, target_batch, model, device):\n    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n    return loss\n\n\ndef calc_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0.\n    if len(data_loader) == 0:\n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        # Reduce the number of batches to match the total number of batches in the data loader\n        # if num_batches exceeds the number of batches in the data loader\n        num_batches = min(num_batches, len(data_loader))\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            total_loss += loss.item()\n        else:\n            break\n    return total_loss / num_batches","metadata":{"_uuid":"d959d023-094d-4b56-a175-a8c30151fcf5","_cell_guid":"48e71382-2dae-4af1-827f-3d3f031be737","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.703579Z","iopub.execute_input":"2025-12-10T13:42:31.703816Z","iopub.status.idle":"2025-12-10T13:42:31.717568Z","shell.execute_reply.started":"2025-12-10T13:42:31.703795Z","shell.execute_reply":"2025-12-10T13:42:31.716907Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## 7.2 Simple Greedy Generation (Training Preview)","metadata":{}},{"cell_type":"code","source":"def generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_emb.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text_simple(\n            model=model, idx=encoded,\n            max_new_tokens=50, context_size=context_size\n        )\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n    model.train()","metadata":{"_uuid":"29f55f0b-0fe1-4bdb-90f3-63c794f29b3d","_cell_guid":"f7c3e21b-4819-471b-83d5-1cf098261749","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.718259Z","iopub.execute_input":"2025-12-10T13:42:31.718520Z","iopub.status.idle":"2025-12-10T13:42:31.731025Z","shell.execute_reply.started":"2025-12-10T13:42:31.718504Z","shell.execute_reply":"2025-12-10T13:42:31.730333Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"## 7.3 Sample Generation Helper","metadata":{}},{"cell_type":"code","source":"def generate_text_simple(model, idx, max_new_tokens, context_size):\n    # idx is (batch, n_tokens) array of indices in the current context\n\n    ###Input batch:\n ###tensor([[6109, 3626, 6100,  345],\n        ##[6109, 1110, 6622,  257]])\n    \n    for _ in range(max_new_tokens):\n        \n        # Crop current context if it exceeds the supported context size\n        # E.g., if LLM supports only 5 tokens, and the context size is 10\n        # then only the last 5 tokens are used as context\n        idx_cond = idx[:, -context_size:]\n        \n        # Get the predictions\n        with torch.no_grad():\n            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n        \n        # Focus only on the last time step\n        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n        logits = logits[:, -1, :]  \n\n        # Apply softmax to get probabilities\n        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n\n        # Get the idx of the vocab entry with the highest probability value\n        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n\n        # Append sampled index to the running sequence\n        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n\n    return idx","metadata":{"_uuid":"42c7a027-1b77-4c5c-a45d-d2ad3ff81893","_cell_guid":"27c9fd1c-815b-4900-9d72-c7249214f138","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.731756Z","iopub.execute_input":"2025-12-10T13:42:31.732070Z","iopub.status.idle":"2025-12-10T13:42:31.748522Z","shell.execute_reply.started":"2025-12-10T13:42:31.732050Z","shell.execute_reply":"2025-12-10T13:42:31.747491Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"## 7.4 Early Stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"\n    Stops training when validation loss stops improving.\n    \n    Args:\n        patience (int): How many evaluations to wait before stopping\n        min_delta (float): Minimum change to qualify as improvement\n        restore_best_weights (bool): Whether to restore best model weights\n    \"\"\"\n    def __init__(self, patience=3, min_delta=0.001, restore_best_weights=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best_weights = restore_best_weights\n        self.best_loss = float('inf')\n        self.patience_counter = 0\n        self.best_weights = None\n        \n    def __call__(self, val_loss, model):\n        \"\"\"\n        Check if training should stop.\n        \n        Returns:\n            True if training should stop, False otherwise\n        \"\"\"\n        # Check if validation loss improved\n        if val_loss < (self.best_loss - self.min_delta):\n            self.best_loss = val_loss\n            self.patience_counter = 0\n            # Save the best model weights\n            self.best_weights = {k: v.clone() for k, v in model.state_dict().items()}\n            return False  # Continue training\n        else:\n            self.patience_counter += 1\n            if self.patience_counter >= self.patience:\n                print(f\"Early stopping triggered! Best val loss: {self.best_loss:.4f}\")\n                # Restore best weights if requested\n                if self.restore_best_weights and self.best_weights:\n                    model.load_state_dict(self.best_weights)\n                    print(\"Restored best model weights\")\n                return True  # Stop training\n            return False  # Continue training","metadata":{"_uuid":"bfa58b85-7361-46d6-bdaf-addba95d4ad9","_cell_guid":"dfb41146-ff64-4182-90a8-1bd9023543a0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.749683Z","iopub.execute_input":"2025-12-10T13:42:31.749928Z","iopub.status.idle":"2025-12-10T13:42:31.764842Z","shell.execute_reply.started":"2025-12-10T13:42:31.749906Z","shell.execute_reply":"2025-12-10T13:42:31.764046Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"## 7.5 Evaluation Helper","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n    model.train()\n    return train_loss, val_loss","metadata":{"_uuid":"b615a68b-37fa-469a-b7df-ab99c2efb7f5","_cell_guid":"0e9512b3-9679-4629-b5b2-819f33d46b53","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.783456Z","iopub.execute_input":"2025-12-10T13:42:31.783735Z","iopub.status.idle":"2025-12-10T13:42:31.800003Z","shell.execute_reply.started":"2025-12-10T13:42:31.783711Z","shell.execute_reply":"2025-12-10T13:42:31.799177Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 7.6 Training Loop with Early Stopping","metadata":{}},{"cell_type":"code","source":"def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n                       eval_freq, eval_iter, start_context, tokenizer, \n                       early_stopping=None):  # ADD THIS PARAMETER\n    train_losses, val_losses, track_tokens_seen = [], [], []\n    tokens_seen, global_step = 0, -1\n\n    for epoch in range(num_epochs):\n        model.train()\n        \n        for input_batch, target_batch in train_loader:\n            optimizer.zero_grad()\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            loss.backward()\n            optimizer.step()\n            tokens_seen += input_batch.numel()\n            global_step += 1\n\n            if global_step % eval_freq == 0: \n                train_loss, val_loss = evaluate_model(\n                    model, train_loader, val_loader, device, eval_iter)\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n                \n                # ADD EARLY STOPPING CHECK HERE\n                if early_stopping is not None:\n                    if early_stopping(val_loss, model):\n                        print(f\"Stopping training at epoch {epoch+1}, step {global_step}\")\n                        return train_losses, val_losses, track_tokens_seen\n\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n        \n    return train_losses, val_losses, track_tokens_seen","metadata":{"_uuid":"94c5e94a-dada-4f1b-82b1-568c5fa414b8","_cell_guid":"f45f430c-a972-4ca7-ab81-aeb67218124c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.765234Z","iopub.execute_input":"2025-12-10T13:42:31.765452Z","iopub.status.idle":"2025-12-10T13:42:31.782567Z","shell.execute_reply.started":"2025-12-10T13:42:31.765430Z","shell.execute_reply":"2025-12-10T13:42:31.781731Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## 7.7 Loss Plotting","metadata":{}},{"cell_type":"code","source":"def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n    fig, ax1 = plt.subplots()\n\n    # Plot training and validation loss against epochs\n    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n    ax1.set_xlabel(\"Epochs\")\n    ax1.set_ylabel(\"Loss\")\n    ax1.legend(loc=\"upper right\")\n\n    # Create a second x-axis for tokens seen\n    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n    ax2.set_xlabel(\"Tokens seen\")\n\n    fig.tight_layout()  # Adjust layout to make room\n    # plt.show()","metadata":{"_uuid":"ebd0b223-92ff-441c-a295-1b783ef5451c","_cell_guid":"04107d02-2472-4718-b92b-242f12e78eca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.800877Z","iopub.execute_input":"2025-12-10T13:42:31.801079Z","iopub.status.idle":"2025-12-10T13:42:31.819725Z","shell.execute_reply.started":"2025-12-10T13:42:31.801064Z","shell.execute_reply":"2025-12-10T13:42:31.818862Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"# 8. GPU Memory Diagnostics & Training Run","metadata":{}},{"cell_type":"markdown","source":"## 8.1 GPU Fragmentation Mitigation","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\nimport torch\ntorch.cuda.empty_cache()\nprint(\"GPU fragmentation fix enabled\")","metadata":{"_uuid":"74e1c52e-4f99-4bde-b34a-b042c50b2600","_cell_guid":"8a4c10ff-05fe-40db-ab0a-21792eede19c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.820323Z","iopub.execute_input":"2025-12-10T13:42:31.820651Z","iopub.status.idle":"2025-12-10T13:42:31.841972Z","shell.execute_reply.started":"2025-12-10T13:42:31.820625Z","shell.execute_reply":"2025-12-10T13:42:31.841355Z"}},"outputs":[{"name":"stdout","text":"GPU fragmentation fix enabled\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## 8.2 GPU Memory Status","metadata":{}},{"cell_type":"code","source":"import torch\n\nprint(\"CUDA MEMORY STATUS\")\n\n# Total GPU memory\ntotal_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\nprint(f\"Total GPU Memory: {total_memory:.2f} GB\")\n\n# Current usage\nallocated = torch.cuda.memory_allocated() / 1e9\ncached = torch.cuda.memory_reserved() / 1e9\nprint(f\"Allocated: {allocated:.2f} GB\")\nprint(f\"Cached:    {cached:.2f} GB\")\nprint(f\"Free:      {total_memory - allocated:.2f} GB\")\n\n# Usage percentage\nusage_pct = (allocated / total_memory) * 100\nprint(f\"Usage:     {usage_pct:.1f}%\")","metadata":{"_uuid":"66b3147d-d661-4bf5-93e0-d3489f823f60","_cell_guid":"ae057f91-64fc-46fd-8dc6-bd95b8ef0733","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.842662Z","iopub.execute_input":"2025-12-10T13:42:31.842933Z","iopub.status.idle":"2025-12-10T13:42:31.853126Z","shell.execute_reply.started":"2025-12-10T13:42:31.842912Z","shell.execute_reply":"2025-12-10T13:42:31.852441Z"}},"outputs":[{"name":"stdout","text":"CUDA MEMORY STATUS\nTotal GPU Memory: 15.83 GB\nAllocated: 0.72 GB\nCached:    0.75 GB\nFree:      15.11 GB\nUsage:     4.5%\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## 8.3 Launch Training","metadata":{}},{"cell_type":"code","source":"import time\n\nstart_time = time.time()\n\ntorch.manual_seed(123)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.15)\n\nnum_epochs = 1\n\n# Initialize early stopping\nearly_stopping = EarlyStopping(\n    patience=10,              # Stop if val loss doesn't improve for 3 evaluations\n    min_delta=0.0001,        # Minimum improvement threshold\n    restore_best_weights=True  # Restore best model weights when stopping\n)\n\n# Train with early stopping\ntrain_losses, val_losses, tokens_seen = train_model_simple(\n    model, train_loader, val_loader, optimizer, device,\n    num_epochs=num_epochs, eval_freq=100, eval_iter=10,\n    start_context=format_input(val_data[0]), tokenizer=tokenizer, early_stopping=early_stopping  # ADD THIS\n)\nend_time = time.time()\nexecution_time_minutes = (end_time - start_time) / 60\nprint(f\"Training completed in {execution_time_minutes:.2f} minutes.\")","metadata":{"_uuid":"374bcb25-fb34-428d-802f-0cb9ad4e3a03","_cell_guid":"06af9505-9129-4ea7-aeeb-24f6ee74e145","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T13:42:31.853849Z","iopub.execute_input":"2025-12-10T13:42:31.854069Z","iopub.status.idle":"2025-12-10T14:17:00.602381Z","shell.execute_reply.started":"2025-12-10T13:42:31.854045Z","shell.execute_reply":"2025-12-10T14:17:00.601732Z"}},"outputs":[{"name":"stdout","text":"Ep 1 (Step 000000): Train loss 3.612, Val loss 3.386\nEp 1 (Step 000100): Train loss 1.734, Val loss 2.311\nEp 1 (Step 000200): Train loss 1.488, Val loss 2.091\nEp 1 (Step 000300): Train loss 1.261, Val loss 1.842\nEp 1 (Step 000400): Train loss 0.856, Val loss 1.586\nEp 1 (Step 000500): Train loss 0.824, Val loss 1.385\nEp 1 (Step 000600): Train loss 0.576, Val loss 1.243\nEp 1 (Step 000700): Train loss 0.553, Val loss 1.089\nEp 1 (Step 000800): Train loss 0.382, Val loss 0.967\nEp 1 (Step 000900): Train loss 0.320, Val loss 0.829\nEp 1 (Step 001000): Train loss 0.291, Val loss 0.716\nEp 1 (Step 001100): Train loss 0.340, Val loss 0.650\nEp 1 (Step 001200): Train loss 0.336, Val loss 0.567\nEp 1 (Step 001300): Train loss 0.235, Val loss 0.481\nEp 1 (Step 001400): Train loss 0.237, Val loss 0.399\nEp 1 (Step 001500): Train loss 0.306, Val loss 0.315\nEp 1 (Step 001600): Train loss 0.167, Val loss 0.294\nEp 1 (Step 001700): Train loss 0.203, Val loss 0.292\nEp 1 (Step 001800): Train loss 0.180, Val loss 0.237\nEp 1 (Step 001900): Train loss 0.165, Val loss 0.241\nEp 1 (Step 002000): Train loss 0.136, Val loss 0.205\nEp 1 (Step 002100): Train loss 0.122, Val loss 0.178\nEp 1 (Step 002200): Train loss 0.139, Val loss 0.156\nEp 1 (Step 002300): Train loss 0.138, Val loss 0.140\nEp 1 (Step 002400): Train loss 0.122, Val loss 0.120\nEp 1 (Step 002500): Train loss 0.124, Val loss 0.113\nEp 1 (Step 002600): Train loss 0.105, Val loss 0.112\nEp 1 (Step 002700): Train loss 0.109, Val loss 0.118\nEp 1 (Step 002800): Train loss 0.098, Val loss 0.107\nEp 1 (Step 002900): Train loss 0.107, Val loss 0.102\nEp 1 (Step 003000): Train loss 0.094, Val loss 0.092\nEp 1 (Step 003100): Train loss 0.095, Val loss 0.095\nEp 1 (Step 003200): Train loss 0.095, Val loss 0.095\nEp 1 (Step 003300): Train loss 0.105, Val loss 0.090\nEp 1 (Step 003400): Train loss 0.102, Val loss 0.087\nEp 1 (Step 003500): Train loss 0.101, Val loss 0.087\nEp 1 (Step 003600): Train loss 0.096, Val loss 0.086\nEp 1 (Step 003700): Train loss 0.106, Val loss 0.087\nEp 1 (Step 003800): Train loss 0.111, Val loss 0.088\nEp 1 (Step 003900): Train loss 0.093, Val loss 0.087\nEp 1 (Step 004000): Train loss 0.102, Val loss 0.090\nEp 1 (Step 004100): Train loss 0.100, Val loss 0.093\nEp 1 (Step 004200): Train loss 0.089, Val loss 0.086\nEp 1 (Step 004300): Train loss 0.092, Val loss 0.086\nEp 1 (Step 004400): Train loss 0.092, Val loss 0.088\nEp 1 (Step 004500): Train loss 0.086, Val loss 0.085\nEp 1 (Step 004600): Train loss 0.088, Val loss 0.085\nEp 1 (Step 004700): Train loss 0.093, Val loss 0.081\nEp 1 (Step 004800): Train loss 0.079, Val loss 0.081\nEp 1 (Step 004900): Train loss 0.100, Val loss 0.080\nEp 1 (Step 005000): Train loss 0.081, Val loss 0.077\nEp 1 (Step 005100): Train loss 0.086, Val loss 0.077\nEp 1 (Step 005200): Train loss 0.092, Val loss 0.078\nEp 1 (Step 005300): Train loss 0.091, Val loss 0.075\nEp 1 (Step 005400): Train loss 0.079, Val loss 0.076\nEp 1 (Step 005500): Train loss 0.091, Val loss 0.077\nEp 1 (Step 005600): Train loss 0.085, Val loss 0.074\nEp 1 (Step 005700): Train loss 0.091, Val loss 0.075\nEp 1 (Step 005800): Train loss 0.082, Val loss 0.078\nEp 1 (Step 005900): Train loss 0.102, Val loss 0.078\nEp 1 (Step 006000): Train loss 0.086, Val loss 0.076\nEp 1 (Step 006100): Train loss 0.097, Val loss 0.086\nEp 1 (Step 006200): Train loss 0.091, Val loss 0.085\nEp 1 (Step 006300): Train loss 0.095, Val loss 0.075\nEp 1 (Step 006400): Train loss 0.088, Val loss 0.073\nEp 1 (Step 006500): Train loss 0.091, Val loss 0.076\nEp 1 (Step 006600): Train loss 0.086, Val loss 0.077\nEp 1 (Step 006700): Train loss 0.091, Val loss 0.079\nEp 1 (Step 006800): Train loss 0.090, Val loss 0.076\nEp 1 (Step 006900): Train loss 0.084, Val loss 0.076\nEp 1 (Step 007000): Train loss 0.083, Val loss 0.076\nEp 1 (Step 007100): Train loss 0.083, Val loss 0.077\nEp 1 (Step 007200): Train loss 0.086, Val loss 0.074\nEp 1 (Step 007300): Train loss 0.083, Val loss 0.073\nEp 1 (Step 007400): Train loss 0.088, Val loss 0.075\nEp 1 (Step 007500): Train loss 0.094, Val loss 0.076\nEp 1 (Step 007600): Train loss 0.093, Val loss 0.075\nEp 1 (Step 007700): Train loss 0.078, Val loss 0.074\nEp 1 (Step 007800): Train loss 0.083, Val loss 0.079\nEp 1 (Step 007900): Train loss 0.081, Val loss 0.071\nEp 1 (Step 008000): Train loss 0.087, Val loss 0.071\nEp 1 (Step 008100): Train loss 0.088, Val loss 0.074\nEp 1 (Step 008200): Train loss 0.084, Val loss 0.071\nEp 1 (Step 008300): Train loss 0.084, Val loss 0.075\nEp 1 (Step 008400): Train loss 0.077, Val loss 0.073\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Respond conversationally and empathetically to show you understand their feelings.  ### Input: I'm stuck on how to make my small apartment feel bigger and more inviting.  ### Response: Small spaces thrive with smart choices: vertical storage (wall shelves), mirrors to create the illusion of space, a cohesive color palette so it feels intentional rather than cluttered, and multipurpose furniture. Add plants for life\nTraining completed in 34.48 minutes.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 8.4 Plot Loss Curves","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\n# epochs_seen: linearly spaced from 0 to num_epochs\nepochs_seen = torch.linspace(0, num_epochs, len(train_losses))\n\n# Create the plot\nplot_losses(epochs_seen, tokens_seen, train_losses, val_losses)\n\n# Show it in the notebook\nplt.show()","metadata":{"_uuid":"488e8950-53ca-4dcb-ab6a-935338fa75fc","_cell_guid":"0b955c58-c4ad-43a4-ad3b-6cb2581d712f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T14:17:00.603154Z","iopub.execute_input":"2025-12-10T14:17:00.603795Z","iopub.status.idle":"2025-12-10T14:17:01.094550Z","shell.execute_reply.started":"2025-12-10T14:17:00.603775Z","shell.execute_reply":"2025-12-10T14:17:01.093881Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAnUAAAHWCAYAAAARl3+JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABzNUlEQVR4nO3dd3xT9f7H8VeSZnQzu9h7yV4WFFBQQEVx8uNyBRX1XgXHxclVASdeRUXFixuuE0UFF4KAoMhQVpUtuyBt2d1N2+T8/ggNVAq0pUna8H4+HueR5OSMT3IKfff7Ped7TIZhGIiIiIhIlWYOdAEiIiIicvYU6kRERESCgEKdiIiISBBQqBMREREJAgp1IiIiIkFAoU5EREQkCCjUiYiIiAQBhToRERGRIKBQJyIiIhIEFOpEREREgoBCnYiIiMhZ+Omnnxg0aBAJCQmYTCZmz55d5m0YhsGkSZNo3rw5drudOnXq8PTTT5dpGwp1IhLUdu3ahclkIikpKdCliEiQys7Opn379rz22mvl3sY999zD22+/zaRJk9i8eTNfffUV3bp1K9M2Qsq9dxERPzGZTKd9f/z48UyYMME/xYiI/MXAgQMZOHDgKd93Op088sgjfPzxxxw9epTzzjuP//znP/Tp0weATZs2MXXqVNavX0+LFi0AaNSoUZnrUKgTkUovJSXF+/yTTz5h3LhxbNmyxTsvIiIiEGWJiJTK6NGj2bhxIzNmzCAhIYFZs2YxYMAA1q1bR7Nmzfj6669p3Lgx33zzDQMGDMAwDPr168dzzz1HjRo1Sr0fdb+KSKUXFxfnnaKjozGZTN7XMTExvPjii9StWxe73U6HDh2YO3fuKbflcrm45ZZbaNmyJcnJyQB8+eWXdOrUCYfDQePGjXn88ccpLCz0rmMymXj77be5+uqrCQsLo1mzZnz11Vfe948cOcKwYcOoXbs2oaGhNGvWjGnTpp2yhs8++4y2bdsSGhpKzZo16devH9nZ2d733377bVq1aoXD4aBly5b897//Lbb+nj17uOGGG6hWrRo1atTgqquuYteuXd73b7rpJgYPHsykSZOIj4+nZs2ajBo1ioKCglJ/5yJSMZKTk5k2bRozZ87kwgsvpEmTJtx///1ccMEF3v8nduzYwe7du5k5cybvvfce06dPZ/Xq1Vx33XVl2pda6kSkSnv55Zd54YUXeOONN+jYsSPvvvsuV155JRs2bKBZs2bFlnU6nQwdOpRdu3axZMkSateuzZIlSxg+fDivvPIKF154Idu3b+f2228HPN26RR5//HGee+45nn/+eV599VWGDRvG7t27qVGjBo899hgbN27ku+++o1atWmzbto3c3NwS601JSWHo0KE899xzXH311WRmZrJkyRIMwwDgww8/ZNy4cUyZMoWOHTuydu1abrvtNsLDwxkxYgQFBQX079+fxMRElixZQkhICE899RQDBgzg999/x2azAbBo0SLi4+NZtGgR27ZtY8iQIXTo0IHbbrvNF4dBRE5h3bp1uFwumjdvXmy+0+mkZs2aALjdbpxOJ++99553uXfeeYfOnTuzZcsWb5fsGRkiIlXItGnTjOjoaO/rhIQE4+mnny62TNeuXY0777zTMAzD2LlzpwEYS5YsMfr27WtccMEFxtGjR73L9u3b13jmmWeKrf/+++8b8fHx3teA8eijj3pfZ2VlGYDx3XffGYZhGIMGDTJuvvnmUtW/evVqAzB27dpV4vtNmjQxPvroo2LznnzySSMxMdFbW4sWLQy32+193+l0GqGhoca8efMMwzCMESNGGA0aNDAKCwu9y1x//fXGkCFDSlWjiJQfYMyaNcv7esaMGYbFYjE2b95sbN26tdiUkpJiGIZhjBs3zggJCSm2nZycHAMwvv/++1LvWy11IlJlZWRksG/fPnr27Flsfs+ePfntt9+KzRs6dCh169blhx9+IDQ01Dv/t99+Y+nSpcWGDnC5XOTl5ZGTk0NYWBgA7dq1874fHh5OVFQU+/fvB+COO+7g2muvZc2aNVx66aUMHjyYHj16lFhz+/bt6du3L23btqV///5ceumlXHfddVSvXp3s7Gy2b9/OyJEji7WoFRYWEh0d7a1327ZtREZGFttuXl4e27dv975u06YNFovF+zo+Pp5169ad5tsUEV/o2LEjLpeL/fv3c+GFF5a4TM+ePSksLGT79u00adIEgD/++AOABg0alHpfCnUick647LLL+OCDD1i+fDkXX3yxd35WVhaPP/4411xzzUnrOBwO73Or1VrsPZPJhNvtBjxXvu3evZs5c+Ywf/58+vbty6hRo5g0adJJ27RYLMyfP59ly5bx/fff8+qrr/LII4/wyy+/eAPkW2+9Rffu3U9ar6jezp078+GHH5607dq1a5eqXhGpWFlZWWzbts37eufOnSQlJVGjRg2aN2/OsGHDGD58OC+88AIdO3bkwIEDLFy4kHbt2nH55ZfTr18/OnXqxC233MLkyZNxu92MGjWKSy655KRu29PRhRIiUmVFRUWRkJDA0qVLi81funQprVu3Ljbvjjvu4Nlnn+XKK6/kxx9/9M7v1KkTW7ZsoWnTpidNZnPp/4usXbs2I0aM4IMPPmDy5Mm8+eabp1zWZDLRs2dPHn/8cdauXYvNZmPWrFnExsaSkJDAjh07TqqlaHiDTp06sXXrVmJiYk5apqg1T0T8a9WqVXTs2JGOHTsCMGbMGDp27Mi4ceMAmDZtGsOHD+e+++6jRYsWDB48mJUrV1K/fn0AzGYzX3/9NbVq1aJXr15cfvnltGrVihkzZpSpDrXUiUiV9sADDzB+/HiaNGlChw4dmDZtGklJSSW2ZN111124XC6uuOIKvvvuOy644ALGjRvHFVdcQf369bnuuuswm8389ttvrF+/nqeeeqpUNYwbN47OnTvTpk0bnE4n33zzDa1atSpx2V9++YWFCxdy6aWXEhMTwy+//MKBAwe8yz/++OPcfffdREdHM2DAAJxOJ6tWreLIkSOMGTOGYcOG8fzzz3PVVVfxxBNPULduXXbv3s0XX3zBgw8+SN26dcv/ZYpIufTp08d7sVNJrFYrjz/+OI8//vgpl0lISODzzz8/qzoU6kSkSrv77rtJT0/nvvvuY//+/bRu3ZqvvvrqpCtfi9x777243W4uu+wy5s6dS//+/fnmm2944okn+M9//oPVaqVly5bceuutpa7BZrMxduxYdu3aRWhoKBdeeOEp/8KOiorip59+YvLkyWRkZNCgQQNeeOEF78Clt956K2FhYTz//PM88MADhIeH07ZtW+69914AwsLC+Omnn3jooYe45ppryMzMpE6dOvTt25eoqKiyfXkiElRMxumipYiIiIhUCTqnTkRERCQIKNSJiIiIBAGFOhEREZEgoFAnIiIiEgQU6kRERESCgEKdD7z22ms0bNgQh8NB9+7d+fXXXwNdkpzgp59+YtCgQSQkJGAymZg9e3agS5ISTJw4ka5duxIZGUlMTAyDBw9my5YtgS5LTjB16lTatWtHVFQUUVFRJCYm8t133wW6LDmDZ599FpPJ5B0mRyqHCRMmYDKZik0tW7Ys0zYU6irYJ598wpgxYxg/fjxr1qyhffv29O/f33uPSAm87Oxs2rdvz2uvvRboUuQ0fvzxR0aNGsWKFSuYP38+BQUFXHrppWRnZwe6NDmmbt26PPvss6xevZpVq1Zx8cUXc9VVV7Fhw4ZAlyansHLlSt54441i9zKWyqNNmzakpKR4p59//rlM62ucugrWvXt3unbtypQpUwBwu93Uq1ePu+66i4cffjjA1clfmUwmZs2axeDBgwNdipzBgQMHiImJ4ccff6RXr16BLkdOoUaNGjz//POMHDky0KXIX2RlZdGpUyf++9//8tRTT9GhQwcmT54c6LLkmAkTJjB79mySkpLKvQ211FWg/Px8Vq9eTb9+/bzzzGYz/fr1Y/ny5QGsTKTqS09PBzyhQSofl8vFjBkzyM7OJjExMdDlSAlGjRrlvXm8VE5bt24lISGBxo0bM2zYMJKTk8u0vm4TVoEOHjyIy+UiNja22PzY2Fg2b94coKpEqj632829995Lz549Oe+88wJdjpxg3bp1JCYmkpeXR0REBLNmzaJ169aBLkv+YsaMGaxZs4aVK1cGuhQ5he7duzN9+nRatGhBSkoKjz/+OBdeeCHr168nMjKyVNtQqBORSm/UqFGsX7++zOeXiO+1aNGCpKQk0tPT+eyzzxgxYgQ//vijgl0lsmfPHu655x7mz5+Pw+EIdDlyCkX3fwZo164d3bt3p0GDBnz66aelPp1Boa4C1apVC4vFQlpaWrH5aWlpxMXFBagqkapt9OjRfPPNN/z000/UrVs30OXIX9hsNpo2bQpA586dWblyJS+//DJvvPFGgCuTIqtXr2b//v106tTJO8/lcvHTTz8xZcoUnE4nFoslgBVKSapVq0bz5s3Ztm1bqdfROXUVyGaz0blzZxYuXOid53a7Wbhwoc4xESkjwzAYPXo0s2bN4ocffqBRo0aBLklKwe1243Q6A12GnKBv376sW7eOpKQk79SlSxeGDRtGUlKSAl0llZWVxfbt24mPjy/1Omqpq2BjxoxhxIgRdOnShW7dujF58mSys7O5+eabA12aHJOVlVXsL5+dO3eSlJREjRo1qF+/fgArkxONGjWKjz76iC+//JLIyEhSU1MBiI6OJjQ0NMDVCcDYsWMZOHAg9evXJzMzk48++ojFixczb968QJcmJ4iMjDzpXNTw8HBq1qypc1Qrkfvvv59BgwbRoEED9u3bx/jx47FYLAwdOrTU21Coq2BDhgzhwIEDjBs3jtTUVDp06MDcuXNPunhCAmfVqlVcdNFF3tdjxowBYMSIEUyfPj1AVclfTZ06FYA+ffoUmz9t2jRuuukm/xckJ9m/fz/Dhw8nJSWF6Oho2rVrx7x587jkkksCXZpIlbN3716GDh3KoUOHqF27NhdccAErVqygdu3apd6GxqkTERERCQI6p05EREQkCCjUiYiIiAQBhToRERGRIKBQJyIiIhIEFOpEREREgoBCnYiIiEgQUKgTERERCQIKdT7idDqZMGGCbpdTiekYVQ06TlWDjlPlp2NUNZzNcdLgwz6SkZFBdHQ06enpREVFBbocKYGOUdWg41Q16DhVfjpGVcPZHCe11ImIiIgEAYU6ERERkSAQEugC/K2wsJC1a9cSGxuL2ey7TJuZmQnAn3/+SUZGhs/2I+WnY1Q16DhVDTpOlZ+OUdXw1+PkdrtJS0ujY8eOhIScPradc+fUrVy5km7dugW6DBEREZFS+/XXX+natetplznnWupiY2MBz5cTHx8f4GpERERETi0lJYVu3bp588vpnHOhrqjLNT4+nrp16wa4GhEREZEzK80pY7pQQkRERCQIKNSJiIiIBAGFOhEREZEgcM6dUyciIlIR3G43+fn5gS5DgoDNZquQYdYU6kRERMooPz+fnTt34na7A12KBAGz2UyjRo2w2WxntR2FOhERkTIwDIOUlBQsFgv16tXz6UD2Evzcbjf79u0jJSWF+vXrYzKZyr0thToREZEyKCwsJCcnh4SEBMLCwgJdjgSB2rVrs2/fPgoLC7FareXejv68EBERKQOXywVw1l1lIkWKfpaKfrbKS6FORESkHM6mm0zkRBX1s6RQJyIiIuXSsGFDJk+eXOrlFy9ejMlk4ujRoz6rCWD69OlUq1bNp/uojBTqREREgpzJZDrtNGHChHJtd+XKldx+++2lXr5Hjx6kpKQQHR1drv3J6elCCRERkSCXkpLiff7JJ58wbtw4tmzZ4p0XERHhfW4YBi6Xi5CQM0eE2rVrl6kOm81GXFxcmdaR0lNLnQ+s2nWYCV9t4ONfkwNdioiICHFxcd4pOjoak8nkfb1582YiIyP57rvv6Ny5M3a7nZ9//pnt27dz1VVXERsbS0REBF27dmXBggXFtvvX7leTycTbb7/N1VdfTVhYGM2aNeOrr77yvv/X7teibtJ58+bRqlUrIiIiGDBgQLEQWlhYyN133021atWoWbMmDz30ECNGjGDw4MFl+g6mTp1KkyZNsNlstGjRgvfff9/7nmEYTJgwgfr162O320lISODuu+/2vv/f//6XZs2a4XA4iI2N5brrrivTvv1Foc4H/kjLYvqyXSzctD/QpYiIiJTKww8/zLPPPsumTZto164dWVlZXHbZZSxcuJC1a9cyYMAABg0aRHLy6RssHn/8cW644QZ+//13LrvsMoYNG8bhw4dPuXxOTg6TJk3i/fff56effiI5OZn777/f+/5//vMfPvzwQ6ZNm8bSpUvJyMhg9uzZZfpss2bN4p577uG+++5j/fr1/OMf/+Dmm29m0aJFAHz++ee89NJLvPHGG2zdupXZs2fTtm1bAFatWsXdd9/NE088wZYtW5g7dy69evUq0/79Rd2vPuCwerKys/DsLk0WEZHKzzAMcgsC8/99qNVSYVdOPvHEE1xyySXe1zVq1KB9+/be108++SSzZs3iq6++YvTo0afczk033cTQoUMBeOaZZ3jllVf49ddfGTBgQInLFxQU8Prrr9OkSRMARo8ezRNPPOF9/9VXX2Xs2LFcffXVAEyZMoU5c+aU6bNNmjSJm266iTvvvBOAMWPGsGLFCiZNmsRFF11EcnIycXFx9OvXD6vVSv369enWrRsAycnJhIeHc8UVVxAZGUmDBg3o2LFjmfbvLwp1PuCwWgBwFuj2MSIiwS63wEXrcfMCsu+NT/QnzFYxv8q7dOlS7HVWVhYTJkzg22+/JSUlhcLCQnJzc8/YUteuXTvv8/DwcKKioti//9Q9V2FhYd5ABxAfH+9dPj09nbS0NG/AArBYLHTu3LlMt2jbtGnTSRd09OzZk5dffhmA66+/nsmTJ9O4cWMGDBjAZZddxqBBgwgJCeGSSy6hQYMG3vcGDBjg7V6ubNT96gNFLXV5aqkTEZEqIjw8vNjr+++/n1mzZvHMM8+wZMkSkpKSaNu2Lfn5+afdzl/viGAymU4bwEpa3jCMMlZ/durVq8eWLVv473//S2hoKHfeeSe9evWioKCAyMhI1qxZw8cff0x8fDzjxo2jffv2Ph+WpTzUUucD9hBPS11egJrjRUTEf0KtFjY+0T9g+/aVpUuXctNNN3m7PbOysti1a5fP9leS6OhoYmNjWblypfc8NpfLxZo1a+jQoUOpt9OqVSuWLl3KiBEjvPOWLl1K69atva9DQ0MZNGgQgwYNYtSoUbRs2ZJ169bRqVMnQkJC6NevH/369WP8+PFUq1aNH374gWuuuabCPmtFUKjzAW9LnbpfRUSCnslkqrAu0MqkWbNmfPHFFwwaNAiTycRjjz1Wpi7PinLXXXcxceJEmjZtSsuWLXn11Vc5cuRImc4lfOCBB7jhhhvo2LEj/fr14+uvv+aLL77wXs07ffp0XC4X3bt3JywsjA8++IDQ0FAaNGjAN998w44dO+jVqxfVq1dnzpw5uN1uWrRo4auPXG4B7X6dOnUq7dq1IyoqiqioKBITE/nuu+9Oufz06dNPGjDR4XD4seLSKWqp04USIiJSVb344otUr16dHj16MGjQIPr370+nTp38XsdDDz3E0KFDGT58OImJiURERNC/f/8y/f4fPHgwL7/8MpMmTaJNmza88cYbTJs2jT59+gBQrVo13nrrLXr27Em7du1YsGABX3/9NTVr1qRatWp88cUXXHzxxbRq1YrXX3+djz/+mDZt2vjoE5efyfB3x/UJvv76aywWC82aNcMwDP73v//x/PPPs3bt2hK/rOnTp3PPPfcUGzDRZDIRGxtb6n3u3buXevXqsWfPHurWrVshn+Ovtu3Pot+LPxIdauW38Zf6ZB8iIhIYeXl57Ny5k0aNGlXKhoVg53a7adWqFTfccANPPvlkoMupEKf7mSpLbgloe/GgQYOKvX766aeZOnUqK1asOGUCLhowsTKzhxR1v6qlTkRE5Gzs3r2b77//nt69e+N0OpkyZQo7d+7kb3/7W6BLq3QqzdWvLpeLGTNmkJ2dTWJi4imXy8rKokGDBtSrV4+rrrqKDRs2+LHK0vEOaVLo9vsVPCIiIsHEbDYzffp0unbtSs+ePVm3bh0LFiygVatWgS6t0gn4mZ3r1q0jMTGRvLw8IiIimDVrVrGrUU7UokUL3n33Xdq1a0d6ejqTJk2iR48ebNiw4ZRNkk6nE6fT6X2dmZnpk89xoqILJcAT7Bw+vDpJREQkmNWrV4+lS5cGuowqIeAtdS1atCApKYlffvmFO+64gxEjRrBx48YSl01MTGT48OF06NCB3r1788UXX1C7dm3eeOONU25/4sSJREdHe6dTBcaKdGKI0wDEIiIi4g8BD3U2m42mTZvSuXNnJk6cSPv27b0jPJ+J1WqlY8eObNu27ZTLjB07lvT0dO90qsBYkawWMxaz51JrDUAsIiIi/hDwUPdXbre7WHfp6bhcLtatW0d8fPwpl7Hb7d4hU6KiooiMjKyoUk9LF0uIiIiIPwX0nLqxY8cycOBA6tevT2ZmJh999BGLFy9m3jzPPfSGDx9OnTp1mDhxIuC52fD5559P06ZNOXr0KM8//zy7d+/m1ltvDeTHKJHDaiEn36UBiEVERMQvAhrq9u/fz/Dhw0lJSSE6Opp27doxb948LrnkEgCSk5Mxm483Jh45coTbbruN1NRUqlevTufOnVm2bJlfzpMrK8exljoNQCwiIiL+ENBQ984775z2/cWLFxd7/dJLL/HSSy/5sKKKU3SxhFrqRERExB8q3Tl1wcLuDXVqqRMRkeDQp08f7r33Xu/rhg0bMnny5NOuYzKZmD179lnvu6K2czoTJkygQ4cOPt2HLynU+YgulBARkcpi0KBBDBgwoMT3lixZgslk4vfffy/zdleuXMntt99+tuUVc6pglZKSwsCBAyt0X8FGoc5HigYgzitU96uIiATWyJEjmT9/Pnv37j3pvWnTptGlSxfatWtX5u3Wrl2bsLCwiijxjOLi4rDb7X7ZV1WlUOcj3luFqaVOREQC7IorrqB27dpMnz692PysrCxmzpzJyJEjOXToEEOHDqVOnTqEhYXRtm1bPv7449Nu96/dr1u3bqVXr144HA5at27N/PnzT1rnoYceonnz5oSFhdG4cWMee+wxCgoKAJg+fTqPP/44v/32GyaTCZPJ5K35r92v69at4+KLLyY0NJSaNWty++23k5WV5X3/pptuYvDgwUyaNIn4+Hhq1qzJqFGjvPsqDbfbzRNPPEHdunWx2+106NCBuXPnet/Pz89n9OjRxMfH43A4aNCggXfEDsMwmDBhAvXr18dut5OQkMDdd99d6n2XR8BvExaUjibTK3cRhtlFXuF5ga5GRET8IT+77OtY7GA59qvYVQguJ5jMYA0983Zt4aXeTUhICMOHD2f69Ok88sgjmEyeAfJnzpyJy+Vi6NChZGVl0blzZx566CGioqL49ttvufHGG2nSpAndunU74z7cbjfXXHMNsbGx/PLLL6Snpxc7/65IZGQk06dPJyEhgXXr1nHbbbcRGRnJgw8+yJAhQ1i/fj1z585lwYIFAERHR5+0jezsbPr3709iYiIrV65k//793HrrrYwePbpYcF20aBHx8fEsWrSIbdu2MWTIEDp06MBtt91Wqu/t5Zdf5oUXXuCNN96gY8eOvPvuu1x55ZVs2LCBZs2a8corr/DVV1/x6aefUr9+ffbs2cOePXsA+Pzzz3nppZeYMWMGbdq0ITU1ld9++61U+y0vhTpfSP6FW/Y/QwtLGzYV/F+gqxEREX94JqHs61w/Hdpc7Xm++WuYeRM0uABu/vb4MpPbQs6hk9edkF6mXd1yyy08//zz/Pjjj/Tp0wfwdL1ee+213ltp3n///d7l77rrLubNm8enn35aqlC3YMECNm/ezLx580hI8HwXzzzzzEnnwT366KPe5w0bNuT+++9nxowZPPjgg4SGhhIREUFISAhxcXGn3NdHH31EXl4e7733HuHhnnA7ZcoUBg0axH/+8x9iY2MBqF69OlOmTMFisdCyZUsuv/xyFi5cWOpQN2nSJB566CH+7/88v8v/85//sGjRIiZPnsxrr71GcnIyzZo144ILLsBkMtGgQQPvusnJycTFxdGvXz+sViv169cv1fd4NtT96gsOz18VkaYcXSghIiKVQsuWLenRowfvvvsuANu2bWPJkiWMHDkS8Nyl6cknn6Rt27bUqFGDiIgI5s2bR3Jycqm2v2nTJurVq+cNdOC5Z/tfffLJJ/Ts2ZO4uDgiIiJ49NFHS72PE/fVvn17b6AD6NmzJ263my1btnjntWnTBovl+P3Y4+Pj2b9/f6n2kZGRwb59++jZs2ex+T179mTTpk2Ap4s3KSmJFi1acPfdd/P99997l7v++uvJzc2lcePG3HbbbcyaNYvCwsIyfc6yUkudLziiAIgiR+PUiYicK/69r+zrWE448b/lIM82TH9pb7l33dnVdYKRI0dy11138dprrzFt2jSaNGlC7969AXj++ed5+eWXmTx5Mm3btiU8PJx7772X/Pz8Ctv/8uXLGTZsGI8//jj9+/cnOjqaGTNm8MILL1TYPk5ktVqLvTaZTLjdFfd7uVOnTuzcuZPvvvuOBQsWcMMNN9CvXz8+++wz6tWrx5YtW1iwYAHz58/nzjvv9LaU/rWuiqKWOl+we0JdpClHd5QQETlX2MLLPllOaFuxhHjmnXg+3em2Ww433HADZrOZjz76iPfee49bbrnFe37d0qVLueqqq/j73/9O+/btady4MX/88Uept92qVSv27NlDSkqKd96KFSuKLbNs2TIaNGjAI488QpcuXWjWrBm7d+8u/nFtNlyu0//ubNWqFb/99hvZ2cfPN1y6dClms5kWLVqUuubTiYqKIiEhgaVLlxabv3Tp0mJ3soqKimLIkCG89dZbfPLJJ3z++eccPnwYgNDQUAYNGsQrr7zC4sWLWb58OevWVVxI/yu11PnCse7XKHLIy1eoExGRyiEiIoIhQ4YwduxYMjIyuOmmm7zvNWvWjM8++4xly5ZRvXp1XnzxRdLS0kp9K85+/frRvHlzRowYwfPPP09GRgaPPPJIsWWaNWtGcnIyM2bMoGvXrnz77bfMmjWr2DINGzZk586dJCUlUbduXSIjI08aymTYsGGMHz+eESNGMGHCBA4cOMBdd93FjTfe6D2friI88MADjB8/niZNmtChQwemTZtGUlISH374IQAvvvgi8fHxdOzYEbPZzMyZM4mLi6NatWpMnz4dl8tF9+7dCQsL44MPPiA0NLTYeXcVTS11vnCs+9VqcuHKzwlwMSIiIseNHDmSI0eO0L9//2Lnvz366KN06tSJ/v3706dPH+Li4hg8eHCpt2s2m5k1axa5ubl069aNW2+9laeffrrYMldeeSX/+te/GD16NB06dGDZsmU89thjxZa59tprGTBgABdddBG1a9cucViVsLAw5s2bx+HDh+natSvXXXcdffv2ZcqUKWX7Ms7g7rvvZsyYMdx33320bduWuXPn8tVXX9GsWTPAcyXvc889R5cuXejatSu7du1izpw5mM1mqlWrxltvvUXPnj1p164dCxYs4Ouvv6ZmzZoVWuOJTIZhGD7beiW0d+9e6tWrx549e6hbt65vdmIYuB+vgRk3jzT5nKdv7Oeb/YiIiN/l5eWxc+dOGjVqhMPhCHQ5EgRO9zNVltyiljpfMJkosEYAYHGW7ZJzERERkfJQqPORwpBIACwFmQGuRERERM4FCnU+UmjzhLqQfIU6ERER8T2FOh9x2zwXS9gKFepERETE9xTqfMR9bKw6a2HWGZYUEREROXsKdT5i2KPIMhwYroJAlyIiIj5wjg0eIT5UUT9LCnU+knrRS5znfJdPGBDoUkREpAIV3Uu0Im+fJee2op+lE+9TWx66o4SPOGyeA5On24SJiASVkJAQwsLCOHDgAFarFbNZ7SNSfm63mwMHDhAWFkZIyNnFMoU6H7GHHAt1BQp1IiLBxGQyER8fz86dO0+6b6lIeZjNZurXr++9D295KdT5SETKUv5nfZbNRj0MY8BZHygREak8bDYbzZo1UxesVAibzVYhLb4KdT5iL0int+V3Qt1O8l1ub8udiIgEB7PZrNuESaWiUOcjIXW7cH/BP/jTqMXrBQp1IiIi4lsKdT5irdmAL9y9cRvgLHBBqDXQJYmIiEgQ0yU7PmIymU64WMId4GpEREQk2KmlzldcBfQLScLkyiSv4IJAVyMiIiJBTqHOV9wuXjUmgg025PwTiA50RSIiIhLE1P3qK1YH+XjOoyvMORLgYkRERCTYKdT5ULYpHIDCnPQAVyIiIiLBTqHOh3LMnlDnzlWoExEREd9SqPOh3GOhzshTqBMRERHfUqjzoTxLxLEnGYEtRERERIKeQp0PORXqRERExE8U6nwoP8QT6sxOdb+KiIiIbynU+VBBUajLzwxwJSIiIhLsAhrqpk6dSrt27YiKiiIqKorExES+++67064zc+ZMWrZsicPhoG3btsyZM8dP1ZZdgS0KgJAChToRERHxrYCGurp16/Lss8+yevVqVq1axcUXX8xVV13Fhg0bSlx+2bJlDB06lJEjR7J27VoGDx7M4MGDWb9+vZ8rLx2XNRKAkAKdUyciIiK+FdBQN2jQIC677DKaNWtG8+bNefrpp4mIiGDFihUlLv/yyy8zYMAAHnjgAVq1asWTTz5Jp06dmDJlip8rLx23zRPqrAVZAa5EREREgl2lOafO5XIxY8YMsrOzSUxMLHGZ5cuX069fv2Lz+vfvz/Lly/1RYpm57Z77vZrd+QGuRERERIJdSKALWLduHYmJieTl5REREcGsWbNo3bp1icumpqYSGxtbbF5sbCypqamn3L7T6cTpdHpfZ2b67/y2lJheNFn9Ppe3qMcrfturiIiInIsC3lLXokULkpKS+OWXX7jjjjsYMWIEGzdurLDtT5w4kejoaO90qsDoC3a7HRcWnIUuv+1TREREzk0BD3U2m42mTZvSuXNnJk6cSPv27Xn55ZdLXDYuLo60tLRi89LS0oiLizvl9seOHUt6erp3qsjAeCYOqwWAvAK33/YpIiIi56aAh7q/crvdxbpLT5SYmMjChQuLzZs/f/4pz8EDT2tZ0ZApUVFRREZGVmi9pxOGk1etr3Bv2r/BVeC3/YqIiMi5J6Dn1I0dO5aBAwdSv359MjMz+eijj1i8eDHz5s0DYPjw4dSpU4eJEycCcM8999C7d29eeOEFLr/8cmbMmMGqVat48803A/kxTslmd9DPsgKceG4VFl4z0CWJiIhIkApoqNu/fz/Dhw8nJSWF6Oho2rVrx7x587jkkksASE5Oxmw+3pjYo0cPPvroIx599FH+/e9/06xZM2bPns15550XqI9wWna7jXEFI4iOqsZ9VkegyxEREZEgZjIMwwh0Ef60d+9e6tWrx549e6hbt65P97Vy12Guf305jWqFs+j+Pj7dl4iIiASfsuSWSndOXTBxhBRdKKGrX0VERMS3FOp8yG4109y0h875qyB9b6DLERERkSAW8MGHg5kjxMLYkI+4yPgNtidApxsDXZKIiIgEKbXU+ZDDaiaTMACMvPQAVyMiIiLBTKHOh+xWCxmGJ9S5czMCXI2IiIgEM4U6Hzqxpa4w92hgixEREZGgplDnQzaLmQzCAXDnqvtVREREfEehzodMJhO5Zp1TJyIiIr6nUOdjeZZj95pVqBMREREfUqjzMaclAgCTUxdKiIiIiO8o1PlYQUhRqMsMcCUiIiISzBTqfCw/xNP9aslXS52IiIj4jkKdjxVai0JdJhhGgKsRERGRYKVQ52MFtigAzEYhFOQGuBoREREJVgp1PmayhVNoHPuadbGEiIiI+IhCnY/ZrRY6O1/no/6rITIu0OWIiIhIkFKo8zGH1UI6EeS6LIEuRURERIKYQp2POUI8X3FegSvAlYiIiEgwU6jzMYfVwi2W7+i74d+wa2mgyxEREZEgpVDnYw6rmfPNG2l5cB4c/CPQ5YiIiEiQCgl0AcHOHmLhc1cvXPV7MrBet0CXIyIiIkFKoc7HHFYz89xdqVa9HgNj2wS6HBEREQlS6n71MYfVc9Wrs1AXSoiIiIjvKNT5mN1qoToZxGeug9T1gS5HREREgpRCnY85QsxcalnNQ3/eBT88GehyREREJEgp1PmY3WohwwjzvMjTbcJERETENxTqfMwRYiaTolCXHthiREREJGgp1PmYw2oh0wj1vHCqpU5ERER8Q6HOxxxWCxmEe16opU5ERER8RKHOxxxWM5lF59Q5M8HtDmxBIiIiEpQU6nzMHmIhk2PdrxiQnxnQekRERCQ4KdT5mMNqxokNp2H1zFAXrIiIiPiAQp2PFd1Rwttap2FNRERExAcU6nzMEeIJdcfHqlNLnYiIiFQ8hTofs1s9X3FG0Vh1GtZEREREfEChzsfsIZ6vOFN3lRAREREfCmiomzhxIl27diUyMpKYmBgGDx7Mli1bTrvO9OnTMZlMxSaHw+GnisvOZDJh110lRERExMcCGup+/PFHRo0axYoVK5g/fz4FBQVceumlZGdnn3a9qKgoUlJSvNPu3bv9VHH5OKwWHi24hR23rIMutwS6HBEREQlCIYHc+dy5c4u9nj59OjExMaxevZpevXqdcj2TyURcXJyvy6swDquZtNwocizRYAnoVy4iIiJBqlKdU5ee7umarFGjxmmXy8rKokGDBtSrV4+rrrqKDRs2+KO8crMfuwLWWegKcCUiIiISrCpNqHO73dx777307NmT884775TLtWjRgnfffZcvv/ySDz74ALfbTY8ePdi7d2+JyzudTjIyMrxTZqb/7+jgsJrpZPqDhKWPwi9v+H3/IiIiEvwqTagbNWoU69evZ8aMGaddLjExkeHDh9OhQwd69+7NF198Qe3atXnjjZLD0sSJE4mOjvZOrVu39kX5p+WwWmhkSiX+jw/hj7lnXkFERESkjCpFqBs9ejTffPMNixYtom7dumVa12q10rFjR7Zt21bi+2PHjiU9Pd07bdy4sSJKLhNHiIX1RkO2thoFHYb5ff8iIiIS/AJ61r5hGNx1113MmjWLxYsX06hRozJvw+VysW7dOi677LIS37fb7djtdu/rjAz/jxNnt5rZYtRnXbNBNGtbttAqIiIiUhoBDXWjRo3io48+4ssvvyQyMpLU1FQAoqOjCQ313Ct1+PDh1KlTh4kTJwLwxBNPcP7559O0aVOOHj3K888/z+7du7n11lsD9jnOpOhCibwCd4ArERERkWAV0FA3depUAPr06VNs/rRp07jpppsASE5Oxmw+3kt85MgRbrvtNlJTU6levTqdO3dm2bJlATlXrrQcVjMWXNiPboW9+6Ful0CXJCIiIkEm4N2vZ7J48eJir1966SVeeuklH1XkGw6rhQhyuXb5jbAcePQAhNgCXZaIiIgEkUpxoUSwc1jNZBF6fIZT938VERGRiqVQ5weOEAsuLOSbjwU73f9VREREKphCnR/YrZ6vOc8S4ZmhljoRERGpYAp1fuA4dvVrrjncM0MtdSIiIlLBFOr8wGH1hLoc87GWujy11ImIiEjFUqjzA8ex7tdsU5hnhrpfRUREpIIp1PlB0eDDWRwLdep+FRERkQqmUOcHRRdKZFJ0Tp1a6kRERKRiKdT5QdE5dZlqqRMREREfUajzg6JQl+E+Nk6dzqkTERGRCqZQ5weOEM/XfNRQS52IiIj4hkKdH9iPtdSluaM9M3IOB7AaERERCUYhgS7gXFA0pMlSVxu4dSEkdApwRSIiIhJsFOr8oOiOEoddDqjbJcDViIiISDBS96sfFF0okVfgCnAlIiIiEqwU6vygqPu10G1QmJcFX90FL3eA/JzAFiYiIiJBQ6HOD4ruKAGQhx22/QBHdsKuJQGsSkRERIKJzqnzA3vI8eycV+gm4tInwRENDS8IYFUiIiISTBTq/MBsNmELMZNf6MZZ6Ibzrgl0SSIiIhJk1P3qJ0UDEOtiCREREfEFhTo/OekK2JTfYd4jsPbDAFYlIiIiwUKhzk/s1qKWOrdnxp5fYPkUWPtBAKsSERGRYKFQ5ydFAxA7i1rqml3iedzzC+QeCVBVIiIiEiwU6vykqPvVWXispa56Q6jVAgwXbFsYuMJEREQkKCjU+YnDWsKFEs0v9Txu/T4AFYmIiEgwUajzk6IBiPMKTwh1zfp7HrfOB7euihUREZHyU6jzE8dfL5QAqH8+2KMh9zD8uTpAlYmIiEgwUKjzE7v1LxdKAFis0OQiz/M/5gWgKhEREQkWCnV+4vB2v7qLv9G8qAtWoU5ERETKT6HOT0q8UAKg6SWACVLXQcY+/xcmIiIiQUGhzk+8F0oU/KWlLqI21Onkea6rYEVERKScFOr85JQtdXD8Ktg/FOpERESkfBTq/OSkwYdP1Kyf53HXEnAV+rEqERERCRYhgS7gXFHUUucsqaUuvgP0fwYaXgAm5WwREREpO4U6PylqqSs2+HARswUSR/m5IhEREQkmahbyE3tICYMPi4iIiFSQgIa6iRMn0rVrVyIjI4mJiWHw4MFs2bLljOvNnDmTli1b4nA4aNu2LXPmzPFDtWfH21JXUvcreM6lS/oYZo+CQqcfKxMREZFgENBQ9+OPPzJq1ChWrFjB/PnzKSgo4NJLLyU7O/uU6yxbtoyhQ4cycuRI1q5dy+DBgxk8eDDr16/3Y+VlVzSkSYkXSoCnC3b+OEj6APau9GNlIiIiEgwCek7d3Llzi72ePn06MTExrF69ml69epW4zssvv8yAAQN44IEHAHjyySeZP38+U6ZM4fXXX/d5zeV12iFNAEwm6HILuJwQGe/HykRERCQYVKoLJdLT0wGoUaPGKZdZvnw5Y8aMKTavf//+zJ49u8TlnU4nTufx7szMzMyzL7Qcjg8+fIpQB3DRWD9VIyIiIsGm0lwo4Xa7uffee+nZsyfnnXfeKZdLTU0lNja22LzY2FhSU1NLXH7ixIlER0d7p9atW1do3aV1vKVOF0qIiIhIxas0oW7UqFGsX7+eGTNmVOh2x44dS3p6unfauHFjhW6/tI4PPnyaljoAZ6bnzhL7N/uhKhEREQkWlSLUjR49mm+++YZFixZRt27d0y4bFxdHWlpasXlpaWnExcWVuLzdbicqKso7RUZGVljdZeENdWdqqZs7Fj66Hta+74eqREREJFiUK9Tt2bOHvXv3el//+uuv3Hvvvbz55ptl2o5hGIwePZpZs2bxww8/0KhRozOuk5iYyMKFC4vNmz9/PomJiWXat795u1/P1FLXqLfncedPPq5IREREgkm5Qt3f/vY3Fi1aBHjOcbvkkkv49ddfeeSRR3jiiSdKvZ1Ro0bxwQcf8NFHHxEZGUlqaiqpqank5uZ6lxk+fDhjxx6/gOCee+5h7ty5vPDCC2zevJkJEyawatUqRo8eXZ6P4jdFF0oUuAxcbuPUCza60POYug5yDvuhMhEREQkG5Qp169evp1u3bgB8+umnnHfeeSxbtowPP/yQ6dOnl3o7U6dOJT09nT59+hAfH++dPvnkE+8yycnJpKSkeF/36NGDjz76iDfffJP27dvz2WefMXv27NNeXFEZFLXUwRmugI2Mg9otAQN2LfF9YSIiIhIUyjWkSUFBAXa7HYAFCxZw5ZVXAtCyZctiAexMDOM0LVbHLF68+KR5119/Pddff32p91MZOI611IFnAOJw+2kWbtQLDmz2dMG2vsr3xYmIiEiVV66WujZt2vD666+zZMkS5s+fz4ABAwDYt28fNWvWrNACg4XZbMJmOcMAxEWKzqvb8aOPqxIREZFgUa5Q95///Ic33niDPn36MHToUNq3bw/AV1995e2WlZPZz3RXiSINe4LJDIe2QsY+P1QmIiIiVV25ul/79OnDwYMHycjIoHr16t75t99+O2FhYRVWXLCxh1jIpPDMAxCHVof49rBvLexcAu2H+KdAERERqbLK1VKXm5uL0+n0Brrdu3czefJktmzZQkxMTIUWGExKPawJeM6rA9ipLlgRERE5s3KFuquuuor33nsPgKNHj9K9e3deeOEFBg8ezNSpUyu0wGBS6gGIofh4daW4oERERETObeUKdWvWrOHCCz3jqX322WfExsaye/du3nvvPV555ZUKLTCYlKmlrv75YLZC+h44vMPHlYmIiEhVV65Ql5OT473d1vfff88111yD2Wzm/PPPZ/fu3RVaYDApGtbEeaYLJQBs4VDv2EUnuruEiIiInEG5Ql3Tpk2ZPXs2e/bsYd68eVx66aUA7N+/n6ioqAotMJgcv/q1FN2vAM0HQLNLITLeh1WJiIhIMChXqBs3bhz3338/DRs2pFu3bt77rn7//fd07NixQgsMJkUtdWcc0qRIz7th2ExoMcCHVYmIiEgwKNeQJtdddx0XXHABKSkp3jHqAPr27cvVV19dYcUFG++FEoWlbKkTERERKaVyhTqAuLg44uLi2Lt3LwB169bVwMNnUOrBh/8q/U8oyIVaTX1QlYiIiASDcnW/ut1unnjiCaKjo2nQoAENGjSgWrVqPPnkk7jdaoU6Fbu3+7UM39Evb8BLreGHJ3xUlYiIiASDcrXUPfLII7zzzjs8++yz9OzZE4Cff/6ZCRMmkJeXx9NPP12hRQaLMg1pUiS+g+eWYQW5vilKREREgkK5Qt3//vc/3n77ba688krvvHbt2lGnTh3uvPNOhbpTKNPgw0XqdIaHdoNDVxWLiIjIqZUr1B0+fJiWLVueNL9ly5YcPnz4rIsKVt6rX8vSUmcJAYsCnYiIiJxeuc6pa9++PVOmTDlp/pQpU2jXrt1ZFxWsHOW9UKKIq6ACqxEREZFgUq6Wuueee47LL7+cBQsWeMeoW758OXv27GHOnDkVWmAwsYd4Ql2Zul/Bc/XrzBFwNBnGbAZzubK4iIiIBLFypYPevXvzxx9/cPXVV3P06FGOHj3KNddcw4YNG3j//fcrusagUXROXZlb6iJiIG0jZKXBgU0+qExERESqunKPU5eQkHDSBRG//fYb77zzDm+++eZZFxaMokKtAKRm5JVtRYsV6p8P2xfCziUQ28YH1YmIiEhVpn48P+rcoDoAG1MyOJqTX7aVG17gedy1pIKrEhERkWCgUOdHsVEOmsZEYBiwfPuhsq3cqJfncfdS0ADPIiIi8hcKdX7Ws0lNAJZuP1i2FePbgy0Cco/A/g0+qExERESqsjKdU3fNNdec9v2jR4+eTS3nhB5Na/G/5btZtq2MLXVF59VtW+A5ry6urW8KFBERkSqpTKEuOjr6jO8PHz78rAoKduc3ronZBDsOZpOSnkt8dGjpV254oSfU7foZEu/0XZEiIiJS5ZQp1E2bNs1XdZwzokOttK0TzW9701m67RDXda5b+pUbXuh5LDqvTuPViYiIyDFKBQHQo2ktAJZtK895dZGQdxTS1lV8YSIiIlJlKdQFQM8mnlC3dPtBDMMo/YqWEGjguYMHu372QWUiIiJSVSnUBUCXhtWxhZhJy3Cy/UB22VYu6oLdqfHqRERE5DiFugBwWC10OTYQ8bKyDm1SNAhxym9QllY+ERERCWoKdQHS89h5dUvLc17dyPlw7+9gMvmgMhEREamKyn3vVzk7PY4NQrx8+yFcbgOLuZQBzWyBet18WJmIiIhURWqpC5C2daKJtIeQkVfI+j/TA12OiIiIVHEKdQESYjHTvXE5bxmWnwNzHoBXO3uei4iIyDlPoS6Aejb1hLoy3zLMGgpb5sKhbbB9oQ8qExERkapG59QFUNHFEit3HSavwIXDaindiiYTXDIBbBHQqLfvChQREZEqQy11AdQsJoLakXachW7WJB8p28rnXQvN+4PV4ZviREREpEoJaKj76aefGDRoEAkJCZhMJmbPnn3a5RcvXozJZDppSk1N9U/BFcxkMnmvgi1zF6yIiIjICQIa6rKzs2nfvj2vvfZamdbbsmULKSkp3ikmJsZHFfqed7y6sl4sAXB4Byx4HH58voKrEhERkaomoOfUDRw4kIEDB5Z5vZiYGKpVq1bxBQVAUaj7fW86mXkFRDqspV/58E74+UUIrw0XjvGMYSciIiLnpCp5Tl2HDh2Ij4/nkksuYenSpadd1ul0kpGR4Z0yMzP9VGXp1KkWSsOaYbjcBr/sOFy2lRteCI5oyD4Ae37xTYEiIiJSJVSpUBcfH8/rr7/O559/zueff069evXo06cPa9asOeU6EydOJDo62ju1bt3ajxWXTo/ydsGG2KDFZZ7nm76u4KpERESkKqlSoa5Fixb84x//oHPnzvTo0YN3332XHj168NJLL51ynbFjx5Kenu6dNm7c6MeKS+eCY6FuydZynFfXapDncdPXYBgVWJWIiIhUJVUq1JWkW7dubNu27ZTv2+12oqKivFNkZKQfqyudnk1qYTbBtv1Z7D1SxjtENLkYrGGQvgdSknxSn4iIiFR+VT7UJSUlER8fH+gyzkp0mJVO9asD8OMfB8q2sjUUml3iea4uWBERkXNWQENdVlYWSUlJJCUlAbBz506SkpJITk4GPF2nw4cP9y4/efJkvvzyS7Zt28b69eu59957+eGHHxg1alQgyq9QvZvXBmDxljKGOoBWV3oeN36lLlgREZFzVEBD3apVq+jYsSMdO3YEYMyYMXTs2JFx48YBkJKS4g14APn5+dx33320bduW3r1789tvv7FgwQL69u0bkPorUp8WnrH2lm07SH6hu2wrN7sULDY4tBUObPFBdSIiIlLZBXScuj59+mCcpmVp+vTpxV4/+OCDPPjggz6uKjDaJERRK8LGwax8Vu0+TI8mtUq/siMKGveBrd97umBjWvqsThEREamcqvw5dcHCbDbR61gX7I9n0wW76asKrEpERESqCoW6SqSoC7Zc59W1uAxMZkj9HY7sqtjCREREpNJTqKtELmzqGdpkS1om+47mlm3l8JrQoKfn+db5FV+ciIiIVGoKdZVI9XAb7etVA+Cnsg5tAtB3PNz+I3S9tWILExERkUpPoa6S6dP8LLpg63WFhA5gMlVsUSIiIlLpKdRVMn1aeC6WWLrtIAWuMg5tciJnVgVVJCIiIlWBQl0l07ZONDXCbWQ6C1m9+0jZN+B2wdf3wqTmumBCRETkHKJQV8mYzSZ6NfOMUVfmW4YBmC1wdDcUZMPGLyu4OhEREamsFOoqobMa2gSg7zi4aQ70uLsCqxIREZHKLKB3lJCS9WpeG5MJNqVkkJaRR2yUo2wbSOjom8JERESk0lJLXSVUI9xGu7rVgHLeXeJEuUeh0HnWNYmIiEjlplBXSfU+dsuwxX/sL/9GlrwIL7WB3z+poKpERESkslKoq6SKhjZZsvUgheUd2sRihfwsWDYF3GcxPIqIiIhUegp1lVT7utWoHmYlM6+QtXuOlm8jnUaAPQoOboGt31dofSIiIlK5KNRVUhaziQubHeuC3VLOLlhHFHS+yfN82asVU5iIiIhUSgp1lVhRF+zP2w6VfyPd/wnmENj9M/y5uoIqExERkcpGoa4Sa1c3GoBtaZkYhlG+jUTXgbbXe54vfaWCKhMREZHKRqGuEmtQM5wQs4nsfBcp6Xnl31DiaM/jpq8h/c+KKU5EREQqFYW6SsxqMdOgZhgA2/ZnlX9DcedBgwvAcMHqaRVUnYiIiFQmCnWVXNOYCOAsQx1At1s9j6v/B4X5Z1mViIiIVDYKdZVcUajbfuAsQ13LKyAyHrL3w6avKqAyERERqUwU6iq5JrUrqKXOYj0+vMmvb53dtkRERKTSUair5CqspQ48oc4cAntWQMrvZ789ERERqTRCAl2AnF5RS93BrHyO5uRTLcxW/o1FxsGF90ONRlCreQVVKCIiIpWBWuoquXB7CAnRDqACumABLhoL7f8PrI6z35aIiIhUGgp1VUCTiuyCFRERkaCkUFcFVNjFEkXys2H5a/DBdeB2V8w2RUREJKAU6qqAChurrohhwOJnYdt82LGoYrYpIiIiAaULJaoAb6irqO5XewT0fghs4VD//IrZpoiIiASUQl0VUBTq9h7JJa/AhcNqOfuN9hh99tsQERGRSkPdr1VAzXAb1cKsGAbsOJAd6HJERESkElKoqwJMJtPxiyUq8grYwnxY+TZMuwycmRW3XREREfE7hboqomlFXwELYDLDiqmweyks/2/FbVdERET8TqGuivDeLqwiQ50lBC56xPN82auQfajiti0iIiJ+pVBXRVT4sCZFWg+G+PaQnwk/v1ix2xYRERG/UairIopC3c6D2RS6KnDAYLMZ+o7zPP/1LUjfW3HbFhEREb8JaKj76aefGDRoEAkJCZhMJmbPnn3GdRYvXkynTp2w2+00bdqU6dOn+7zOyqBOtVDsIWbyXW72Hsmt2I036QsNLgCX0zMosYiIiFQ5AQ112dnZtG/fntdee61Uy+/cuZPLL7+ciy66iKSkJO69915uvfVW5s2b5+NKA89sNtHYFxdLAJhM0G+853nSh3Dgj4rdvoiIiPhcQAcfHjhwIAMHDiz18q+//jqNGjXihRdeAKBVq1b8/PPPvPTSS/Tv399XZVYaTWMi2JSSwbYDWfQjtmI3Xq8btLgMtsyBRU/BDe9V7PZFRETEp6rUOXXLly+nX79+xeb179+f5cuXn3Idp9NJRkaGd8rMrLrjsflkWJMTXfwYYIKNX8Kfq32zDxEREfGJKhXqUlNTiY0t3kIVGxtLRkYGubkln2c2ceJEoqOjvVPr1q39UapP+OwK2CKxraHdEM/zhU/4Zh8iIiLiE1Uq1JXH2LFjSU9P904bN24MdEnl5h2r7kAWhmH4ZicXjQWzFXYs9kwiIiJSJVSpUBcXF0daWlqxeWlpaURFRREaGlriOna7naioKO8UGRnpj1J9omGtMMwmyMwr5ECm0zc7qd4Qutzsef7TJN/sQ0RERCpcQC+UKKvExETmzJlTbN78+fNJTEwMUEX+ZQ+xUL9GGLsO5bBtfxYxUQ7f7KjXAxBaA7rd7pvti4iISIULaEtdVlYWSUlJJCUlAZ4hS5KSkkhOTgY8XafDhw/3Lv/Pf/6THTt28OCDD7J582b++9//8umnn/Kvf/0rEOUHhPe8ugM+Oq8OICLG0w0bXtN3+xAREZEKFdBQt2rVKjp27EjHjh0BGDNmDB07dmTcOM8dDlJSUrwBD6BRo0Z8++23zJ8/n/bt2/PCCy/w9ttvnxPDmRRp4uuLJUpSUMGDHYuIiEiFC2j3a58+fU57wn9Jd4vo06cPa9eu9WFVlVvRsCbbfdlSVyTlN5g7FsJqwpD3fb8/ERERKbcqdU6d+LmlzmKD3UvBYofsgxBey/f7FBERkXJRqKtiis6pS8twkpFXQJTD6rudxbSCK1+Fpv0U6ERERCq5KjWkiUCUw0pMpB2A7f5ores0HKISfL8fEREROSsKdVWQz+8scSrZB/27PxERESk1hboq6PidJbL9s8Pco/Dh9fByB8g94p99ioiISJko1FVBTY5dAbs5NcN3tws7kSMaMvZBfiasfNv3+xMREZEyU6irgprHem51tnjLAa6duozFW/b7NtyZTNDzXs/zFa9Dfo7v9iUiIiLlolBXBXVtWJ1bL2iEPcTMmuSj3DRtJYNfW8rCTWm+C3dtroZq9SHnICR96Jt9iIiISLkp1FVBIRYzj17RmiUPXsStFzTCYTXz2950Rv5vFVe8+jNrk31w3pslBHrc7Xm+9BUodFb8PkRERKTcFOqqsJgoB49e0ZqfH7qYf/RuTJjNwoZ9GdzxwRrftNh1/DtExEJ6Mvz6ZsVvX0RERMpNoS4I1IqwM3ZgK5Y8eBGhVgupGXls9cVwJ9ZQ6Ou5Ly8/PqchTkRERCoRhbogUjPCTpeG1QFYus1Hgav93yCuHTgz4IenfLMPERERKTOFuiDTo4nndl7Lth/yzQ7MZhjwrOf5mv9B6nrf7EdERETKRKEuyPRsWhOAFTsOUehy+2YnDXtC66vAcMO8f4M/xsoTERGR01KoCzJtEqKJcoSQmVfIhn0ZvtvRJU+AxQY7f4Qt3/luPyIiIlIqCnVBxmI2cX5jT2vd0u0+vJChekNIHOV5vmeF7/YjIiIipaJQF4R6NPGEuuW+Oq+uyIX3wS3fe1rtREREJKAU6oJQz6aeiyVW7jqMs9Dlux3ZI6F+d99tX0REREpNoS4INY2JoFaEnbwCN2uTj/pnp0eTYe0H/tmXiIiInEShLgiZTCZvF+wyX41Xd6L0vTClK3w5GjZ94/v9iYiIyEkU6oJU0dAmPhuv7kTRdaHzTZDQARr08P3+RERE5CQhgS5AfKNoEOKkPUfJdhYSbvfxoe4/EQpywB7h2/2IiIhIidRSF6Tq1QijXo1QCt0Gv+467Psdms3FA92vb8G2Bb7fr4iIiAAKdUGtR2NPa53Phzb5q81zYM79MGMY7Fzi332LiIicoxTqgliPY+fVLfXHxRInatoPmg+Ewjz4aAgka3BiERERX1OoC2KJx66A3ZiSwZHsfP/tOMQG10+HJhdDQTZ8eD0c3Oq//YuIiJyDFOqCWEykg2YxERgGrNjh5y5YqwOGfAj1zgdnBnzyd3Bm+bcGERGRc4hCXZAruruEX4Y2+StbGNzwHkTEwYHN8NVdYBj+r0NEROQcoFAX5Iq6YJdu9/N5dUUiY+GG/4E5BDZ8ASumBqYOERGRIKdQF+TOb1QTswl2HMgmNT0vMEXUPx/6P+N5/v2jsHtZYOoQEREJYgp1QS46zMp5daIBWBao1jqAbrdD2+vBcMHMmyAzNXC1iIiIBCGFunNAURdsQM6rK2IywaCXIaYNZKXBpyPAVRC4ekRERIKMQt05oOexW4Z9sWYvf3/7Fz5dtYf03AAEKls4DHkf7NGwZwXsWOz/GkRERIKU7v16Dji/cU0ubFaLJVsP8vM2z/TorPVc1LI2V3Wow8UtY3BYLf4ppmYTuPYtz1WwzS7xzz5FRETOAQp15wBbiJn3R3Yn+VAOX/++j9lr/2Tr/izmbUhj3oY0Ojeozsx/JGI2m/xTUPP+/tmPiIjIOaRSdL++9tprNGzYEIfDQffu3fn1119Puez06dMxmUzFJofD4cdqq676NcMYdVFTvv9XL76750L+2bsJoVYLq3cfYcXOAJ1vd2Q3fDkKCgJ0Za6IiEiQCHio++STTxgzZgzjx49nzZo1tG/fnv79+7N///5TrhMVFUVKSop32r17tx8rrvpMJhOt4qN4eGBLBnesA8Bnq/f6vxC3Cz64BtZ+AD886f/9i4iIBJGAh7oXX3yR2267jZtvvpnWrVvz+uuvExYWxrvvvnvKdUwmE3Fxcd4pNjbWjxUHl+s61wXgu3WpZDkL/btzswUG/gfqdoPu//DvvkVERIJMQENdfn4+q1evpl+/ft55ZrOZfv36sXz58lOul5WVRYMGDahXrx5XXXUVGzZs8Ee5QalT/Wo0rh1OboGLOb+n+L+Apv3glnlQrb7/9y0iIhJEAhrqDh48iMvlOqmlLTY2ltTUkgenbdGiBe+++y5ffvklH3zwAW63mx49erB3b8ndh06nk4yMDO+UmZlZ4Z+jKjOZTN7Wupmr9wSmCPMJP4Y7foSC3MDUISIiUoUFvPu1rBITExk+fDgdOnSgd+/efPHFF9SuXZs33nijxOUnTpxIdHS0d2rdurWfK678ru1UF7MJVu46ws6D2YErZMkL8N6VMPfhwNUgIiJSRQU01NWqVQuLxUJaWlqx+WlpacTFxZVqG1arlY4dO7Jt27YS3x87dizp6eneaePGjWddd7CJjXLQq3ltAD4PxAUTRRI6ASZYPR2SPg5cHSIiIlVQQEOdzWajc+fOLFy40DvP7XazcOFCEhMTS7UNl8vFunXriI+PL/F9u91OVFSUd4qMjKyQ2oNNURfs52v24nIbgSmiyUXQ+yHP82/uhZTfA1OHiIhIFRTw7tcxY8bw1ltv8b///Y9NmzZxxx13kJ2dzc033wzA8OHDGTt2rHf5J554gu+//54dO3awZs0a/v73v7N7925uvfXWQH2EoNCvVSzRoVZS0vNYtv1g4Arp/RA0vQQK8+DTGyH3SOBqERERqUICHuqGDBnCpEmTGDduHB06dCApKYm5c+d6L55ITk4mJeX4VZlHjhzhtttuo1WrVlx22WVkZGSwbNkynSt3lhxWC1e2TwBg5qoAdsGazXDNm56rYY/sgi/+AW534OoRERGpIkyGYQSory0w9u7dS7169dizZw9169YNdDmVyu97j3LllKXYQ8z8+kg/okOtgSsm5Td451JPi91Fj0DvBwNXi4iISICUJbcEvKVOKo+2daJpERuJs9DNN7/vC2wx8e3h8hc9zxc9A1sXBLYeERGRSk6hTryKjVkXyC7YIh2HQeebAAM+H+npjhUREZESKdRJMYM71sFiNpG05yjb9leCgZoHPucZ6iTvKHw6HAryAl2RiIhIpaRQJ8XUjrRzUQvPmHUzAzlmXZEQO9zwHoTW8Jxn990Dga5IRESkUlKok5Nc17ke4OmC3X0ogHeYKFKtHlz3DljDod75ga5GRESkUlKok5Nc3DKG5rERHM7OZ8gbK9hxICvQJUGTi+HedZ7z7EREROQkCnVyEluImQ9u7U6zmAhSM/IY8uYKtqZVgvPrwmsef559CHKPBqwUERGRykahTkoUE+lgxu3n0zIukgOZTv7vzRVsSsko83byClxs25/F/sw8nIWuiinuz9XwRi+YfSecW8MsioiInFJIoAuQyqtmhJ2PbzufG9/9hfV/ZjD0rRV8MLI759WJLtX6S7cd5J4ZazmYle+dF2q1EB1qJTrUSuuEKCZe0xaH1VLGykyQvR8OboHsAxARU8b1RUREgo9a6uS0qofb+PDW82lfrxpHcwr421srSNpz9LTruNwGLy/Yyt/f+YWDWfk4rGZMJs97uQUuUjPy2JKWyay1f/LfRdvKXlSdTvC3T+C2RQp0IiIix6ilTs4oOtTKByO7cfO0lazafYRrpy6jf5tYbunZiM4NqmMqSmzAoSwn936SxJKtBwH4v671mHBlG2wWM5nOQtJzCkjPLeDXXYd58puNTP1xO5e3S6BFXGTZimpy8fHn2Ydg7XvQejDUaFQBn1hERKTq0b1fpdSynYX865Mkvt+Y5p3Xtk40t1zQkMvbJvD73qOM/mgtqRl5OKxmnhrc1nuHir8yDIPb3lvNgk1pdKxfjc/+2QOL2VTisqdiGAbPzt1MxPoPuSv7Vc/M+A7Q5mpoMxiqNyzfBxUREakkypJbFOqkzDanZjB96S6+WPsn+YVuAGpF2DiSU4DLbdC4djhTh3U+Y+tbSnoul7z4E1nOQh6/sg0jejQsdQ2GYfDMnE28tWQnfcxrGVdzEY2z1oDhPr5QrRYQWg1CHMcmO1hDITIeetxd/GpaERGRSkih7jQU6irOoSwnH/+azPsrdpOW4QRgUPsEJl7Tlgh76Xr231++i8e+3EC4zcL8Mb1JqBZaqvVeWbiVF+f/4X0darWw/K62VNs9FzbOhl0/Fw94f1W3G4z8Hkxlax0UERHxp7LkFp1TJ+VWM8LO6IubcXuvJszfmIbZBAPOiyt2jt2ZDOvegNlJ+1i9+wiPzV7P2yO6nHH9d3/e6Q10j13Rmi/W7GXDvgym/57Nvf1GQteRkLUfUn6HwlzP/WILj00FubD2fbj0SQU6EREJKgp1ctZsIWYubxdfrnXNZhPPXtOWy15ZwsLN+/l2XQpXtEs45fKfrtzDE99sBGDMJc0ZeUEjYiLt3PXxWqYv28XtvRoTZgvxXBXbrF/JGzn/TrCc8KOfsQ+iTr1PERGRqkBDmkjANYuN5I4+TQGY8NVG0nMKSlzum9/38fAXvwNw24WNuOtizzoDz4ujfo0wjuYU8MnKPWfe4YmBLnUdTOkK88eD+zTdtSIiIpWcWuqkUhh1URO+/X0f2w9kM3bW71zaOo68ApdnKnRzNKeAt5fswG3A0G71+PdlrbzdtCEWM7f3asyjs9fz9pKd/P38Blgtpfx7ZecSyM+CfWvAcAFmWP85JH0MuUcg97DnrhVdboHu//BcbCEiIlIJKdRJpWAPsfDste24/vXlzFmXypx1qSUud2X7BJ4a3Pak8+6u61yXyQv+4M+juXz92z6u6VTKi2AS74ToOtCoF1isnnlH98C2+cWXm/8YrHoHLnkCWl2p8/FERKTSUaiTSqNrwxo8enkr5m1IxR5iwWE1Y7dasIeYcVgtNKkdwfDEBiWOZ+ewWri5ZyOen7eF13/czuAOdTCXdty71lcVf93sEgirCWE1ILQGHNoKPzwNR3bBp8OhQU/o/zQkdDz7Dy0iIlJBNKSJBI303AJ6PvsDWc5C3hnRhb6tYk9a5mCWkz/SMulQr5rngorScmbB0pdh2aueK2oB2g+FC++DWs0q6BOIiIgUV5bcogslJGhEh1oZ1r0+AK//uL3Ye7n5Ll5duJVezy3ib2/9QpenFjDm0yR+3noQl7sUf9fYI+DiR+CuVdBuiGfebx/DlC7w/tWQn1PRH0dERKRMFOokqNxyQSNsFjMrdx1h1a7DuN0Gs9bu5eIXFvPC/D/IyXcR6QghJ9/FF2v+5O/v/EKPZxcycc4mNu7L4IwN19F14Zo34dYfoPlAwAT52WALO75MYb5PP6OIiEhJ1P0qQefhz39nxso9dKpfjUK3we970wGoUy2Uhwa25Iq28azdc4Qv1vzJN7+nkJ57fAiVmuE2ujSsTteGNejasAZtEqIIOd2VtId3Ql46JHTwvM457Gm9a3wRDJ4KITYfflIREQl2uqOEnNNu79WYT1btYU3yUQAi7CHceVETbunZCIfVAkDnBjXo3KAG4wa1ZtHmA3yxZi8//nGAQ9n5zNuQxrwNaQCE2Sx0blCdG7rUY+B5cScHvBqNir/e+CXkHIJD24oHuj0rIa4tWB2++tgiInKOU6iToNO4dgT/17U+n6xM5v+61edf/ZpTO7Lk8eXsIRYGnBfHgPPicBa6WP9nOit3HWHlzsOs3HWYjLxClmw9yJKtB0mIdjC8R0OGdq1PdJi15J13vskT3gpOOMcuLx2mXwYWGzTo4bl6tkFPT+ue5RTbERERKSN1v0pQcrsNCtxu7CGWs9rG1v1ZzFmXwoe/7OZgludcuVCrhes61+Wmng1pUjvizBvat5bCj4cRkvlnsdkuSyhZMZ3IiT+f6h0G4ajXQePfiYhIMWXJLQp1IqWQV+Diq9/28e7PO9mcmumdX69GKB3qVad93Wg61q9Gm4RoHFYLh7KcLN9xiGXbD7Fs20F2H8qitWk33c2b6W7eRDfzZqqbsortI80cy+7YvoS0uZLmXfoS4dD5eCIi5zqFutNQqJOzYRgGy7cf4t2lO1m4eT9//dcTYjaRUC2U5MPFhzgxm6B1QhRh1hDyXW4KCwtJKEimTf7vtCtI4nx3EqGm41fNJhsxjK75Fg6bHafLTYJzB4dcYaS6oyl0m2hTJ5q+LWO4uGUMMVElnKdXmA/Z+yErDbIPQkQM1GpR/CpdERGp9HShhIiPmEwmejStRY+mtcjIK+D3Pekk7TlC0p6jJO05ysGsfG+gaxEbSY+mNenZpBbdGtcgylHy+XOGYfDn/kPs/vVrHNvm0Dz9Zza6G/D7vmwgG4D37Q8QZcqlr/N5ko067EvPo8mWtzj0zTLSbTYiQkOJDHNgzU/HkrOfEOfRk/eDCXfTS7H8/dPjM/esBEcU1GhCvmEm+XA2uw7mUD3cRuv4KEJt5e++PpUsZyG5+S7CbBZCrZbS3/mjFApcbvYcziElPY/D2fkcycnncHY+R3MKOJydjy3EzAVNa9GreW1qhKslVESCi1rqRCqIYRjsPZLLrkPZtIyLOuXFGWdUmE9qWgpJR2y4DXBQQM85/bDlHSTpb0kUWiNYvv0QTVZO4PK8b065mXzDwkGiOWJEEmc6TE1TJl+6evBy9EO0iIukee1Q7l3eAxMGV4VNZ92x/d1t+YIelg1sN+qQEdGIkJgW1GjYjqZNmlM93E6B201hfi7u3EzceZkYzkwKQyLIj6qPyQQmw03Ykc1gMrHHUo8dhwvYdTCbnQez2XEwm4NZzmJ12kPMhNkshNlCsIeYsVrMhFhMWC1mrMceQ60WokOtRIVaiT5hyit0sfPA8W0nH84p1WDSJhO0q1uN3s1r06dFbVrERvLn0Vx2HdvG7kM57DqUzeHsfEIsZqxmk7cum8VMuM1C09hImsdG0jw2ggY1w0u8fZ2/FLrcpx9655hDWU6+35jGrzsP0zQmgr6tYmgRG3nSvZSDxZ7DOSzYlMaiLQdwuw26NarB+Y1r0r5edInn2xqGwYEsJ3+kZpHlLKR2pJ3aEXZqR9pL/APH5TbIyiskI88zLFLtSLv3Cns5Lr/Q7f13b7WYsVnM2EI8/74tZlPQ/vxVFHW/noZCnVRZbheYT/iFcXArR1J2sC75IBv2HOKP1CNkEkGevRYFjlpYwqoTGWYj3B7Cn0dy2Z+6l/zcbP6kNgAR5PCN7RGqmbLo4pxKISFE2EN41f4aF+X/eNLuswwH+YQQQS42k6vYe5+7LuS+gjsAcOBks+NmANrnvUk6notJHgiZwSXm1RwhkkwjlDzs5GEj17CRi508rBQYIRiYvNMOI5657m7e/fzdMh+AWa4LyCYUgC6mzbQyJ2PFRQiFhFoMqoeaCbeaCbV6AmGo1USo1UxOvotdh/NIyoxkpquPd7sjLPOoaUrnf4X9OUQ0AIPMy7ja8jPhpjwiySWCHMJNeUSQiwU3B6hGmlGNNKMGB001KAyPIzeqMb+GXkC2s5DcAhcds38mpDCbH13tOWyKxjAM2hub6WEkYSff8z3awjDbI7GERmILiyI0vBqO8ChcmCh0GxS6IQ8rf0a0I6/AxcGsfPLS09if7WJPtoUDWZ59NaoVTod61ehYvxod6lWjZVwUthAzaRl5zNuQypx1Kfy68zB/zbx1qoXSt1UMfVvFcn7jGthDLDgLXaTnFHA0t4CjOQUcyclnf6aT/Rl5pKbnkXbs+f5MJy634Q3fIRYTVrMnmNepHkrr+ChaxUfRKj6ShjXDva2yOfmF/JGWxeaUDDanZrI5NQOAmuF2akbYqBFuo2aEnZrhNvIL3RzIdHIgy8mBTCf7M/M4kOnEYbXQsGY4DWuG0aBmOA1reR6TD+ewYGMaCzftZ0taJiVxWM10blCd8xvVpFqYlT/SstiSlsnWtEyO5BTQ2rSLeqb9bDcS2GZ4fk/UsrvoFbqDgpBI/iiIYV+ejUxn4UnbrhFuIy7KQXy0g9hoB1EOK7n5hWTnu8jJLyQn30WO00Wh202ko/gfKdGhVmwhZu93fig7nyPZntbmLGchFrOJELMnCIVYTISYPeEoNspBXJSd2CgH8dGhxEXbqR3hwGz29C6YTWDC5Pmj69hzswnMJhNmkwmTGQzDc+5wzrE6c/M9z52FbhzW4394hdtCCLNbcFgtZOYVFGsJP3qs5rQMJ2lFPysZeRzKPvWA7Baziaa1I+jcsDqd61enS8Pq1K8RVmLQMwyDLGchBniCocVcrKXf7TY4nJPv+XkpmrKc5BW4cLkN71R47NFhtVAtzEq1UCvVwqxEh9q8xwAM3Ibne3EbBobhGR4rJsr/wV2h7jQU6uRcdWIrxObUDLYfyCLSYaVRrXAa1Qqnce1wakfYMR3YgrFvLdl/biT7z42EHNlGdO4eQnCdtM0cHOSaQlkY0ovX7bdgAFZ3Hh/l/hMDE7fV+B8Na0fSsFY41+98jDp/zi1TzWnxF7Oi+xRy8l1k5BZw6+JuWIxCHm30KbsLqxFiNvHP3Lfovv/TM2/sBPkJXZndaRo/bjnAT1sPMN/4B3GmI9wd/Qqu2LY0qBHGwMMf0PaPV8u03Y3uBlyWP9H7erHtXzQ0p3GNcwJrjOYAjLR8y2PWD8u03T+NmvR0Hq9lpm0CXc1/8M/8e72h9wrzch6xfuiNxGYMLGYTBW4oxILbMFOIGWuIFbvdRqbLxr48K3/Pfxjw/GK8wfYzzUx/Mju/GxsMzxiMTU17ud7yIxbc3ikEF+Zjz/Oxko2DHOxkGw5yjz3Ocl/g3W5v82+0DEkhrUZXfi+sz85D2cQZh7jO8iNmDMwmA6cR4lkXBzmGZ3s5OHAbJiwmt3d/K9ytycdzKsP55o20Ne1gjbsZq40WAMRwhIetH+P5xWamRoSDhGqhmCxW/sxyszvdRXqBmXzDihMrUaZsGptSub/gH+Rhx2yCV8Knc0Xh97wXci1P512Ps9BNQ1MKi+33eY/BQSOKXUYcO91x7DHFs49aZLps5GD3/qGSi509RgwFx850amlKpqnpT7YbCWwyGgBQnQxutCzAairESiE2PI9WCrGail57vu88bOQYnu2+XXiZ9w+0jqatdDb/wWajPj+72wJgJ5+/WRZiAkwU/Zo3vK/N3j+dwIQbMJGLjfnuLuw1PNutSTp1TAc5QgR7jOP30o7nEAZgNxUQhpNQnISZnISRh4N8bKZCQnB5JwsufqIzu0kg3+Wmrmk/F5jXk2ZUZ5G7o3e7Pc3rsOAmzBFK49hoIky5GDmHseQdxZp/FEfBUSLJJt0IZ69Rmz1GbdbTlIMhsVgtZrKchSW21JtxE0YeYTgJN3kew8jDhZlc7J6ftWPfaw4OzLgBKDx23KLJoo15F/lGCKuMltQItxEb5aB1WLqnFbdmA0b2akyE3TdntOmcOhE5iclkIibSQUykgwua1Tr1gjEtMcW0JKIDeAdsKcyHI7vAcHvug2uPBFsEYWYLYcANx6bjdgEw+8RZhyfC0Ts9gzPnZ0FBrmc8v4Lc489dBcCxP48xiI1rx1Ud6hzfxoGrwFXAU1d2g9Dqnnlrt8JWJ5itYA4BSwiYLGAyH2uWMAOm48PFGG5s1RpwQ5d63NClHoUuN665/4dBIa/0vAiqee4fTMoN0Kol2I593qLJFuHZZlYqZKbiTt9HxoE9ZB/cA+5QnmvbjlCbhXC7hbCVF5KZt58XevaisKYn1IXtC+Ho9hCMkFBcJgv5OVkU5GbgyvV0ZZsKsrEU5njCzrHAkx1SkyFt62ELMVMj3EbjdRbIgH9d0ZmHm/chzGbh8M+7iP/1cPFjaVCUq44/uoFcqA00Co3k7f/rysLNnpatK/KW0Mu8jo2mBDbRiOhQK91tR/lH3ren/nk5hU6XjGRjWi4b92Vw/f4lXGFexhMHDHa4agLQOjyD+1yflXm7c/ovJrJWXbKdLuotn0WbP2fyecTfSCloz770POLtTq4x/Xx8hdxjE9C8aF4Jv/kcfR8irllnmsZE4Fh3GNYcZXiHC7mx8wCynIUc+XMbOV83x5J3BHveAWqZMqhlyqCL+Y/jGymhAeeV8z6jIKo+YbYQ+uz4hlbJH7GtxT/Y1vYaT7ftoW3csLzs38N5V9xJelQrcgpcJPz2M112fMjP0ZeT5+hFakYeBVm5jLe8X+bt/mnUx2mrS5jNwtXuZdybO4Wl1vMZa32YnPxCsp0ufjLfi9V08h95p2Nc1w/TeQMxDAPX+tmEfP42hXXPJ+26+1i3N501yUe4c+WdVDOOen5GU0rYSAnf72MFN/F+/qWAi4vMa3nRPpWNpqY8We1JakfaqRVh56k/riTclV6mep803c4s86WYgO7GXv7rfoYdRgIXOydx+Fjr6Uu2h2lp3kPjvA+4rXfjMm3fV9RSJyJSFRU6PeHVciyhZB+C9GTAhGEy8efRPPYcyaVZ7XBqhVk83feGy/PoLvAEaXchtBoEeLquDi2agj0zGXO76wlr2NXTtbV/E6z9wBOYzZZjj8eem8yewJ+f5bkHckHO8edDZ0CI57xS94o3yN6+jE21B+Js1NdzzmnBn7D0lePhu9B5bP3s4pPhPravY/u7cRZEeFqS+G0GbP8BWgyENleTV+AiJO8wIetmeP4wMNyAcewzu8Dl9Oyn0AmFeeDKB2sY1GwCba+HyLjSfffOTDi8w3PnmEPHHrNSPd9pfs4Jf6xkw6iVEHmslWvl27B+FrS9Frrccvy4LXrK80eJpWiyH3u0HZusnu+oIO/4trv/8/j3sPlb2DAbGl0InYZ75uVnw1d3e56bPO1x3ucm87G2OxOGydNmh+HG7MrD1PshqO1p9STpY/jhKWjWDwa97JlnGBhPx3n+ALOGYrKGea6qt0V4vktrqKfmoj+wzCGez9btNqh37FSK3cth2Sue/fSbcPx7fe8q3NmHcTrzcObnUxgShttRHVNodczhNbFF1sQRWQNT7hGMo7vhyG4yezxMVnwP8l1uau2dT7WvboK6XeHWBce3+9J5kL7H8zNki/DUaw3z/HwU5Bw7Zsd+1opc+hT0uMvzPOV3mPUPjFrNOHr526Rm5JGakUf7b68kImsXT7dfwONXnVe6n51yUPfraSjUiYiIBCFnJmTs8wS2avWOz889AiGhnj8yTnVRhmF4gn5+DpjNYIs8/gdTgJUlt5z5cik/eO2112jYsCEOh4Pu3bvz66+/nnb5mTNn0rJlSxwOB23btmXOnDl+qlREREQqJXukp/XvxEAHnlM1rI7T37HHZPK0MobX9CxfSQJdWQU81H3yySeMGTOG8ePHs2bNGtq3b0///v3Zv39/icsvW7aMoUOHMnLkSNauXcvgwYMZPHgw69ev93PlIiIiIpVHwLtfu3fvTteuXZkyZQoAbrebevXqcdddd/Hwww+ftPyQIUPIzs7mm2+Oj891/vnn06FDB15//fUz7k/dryIiIlJVVJnu1/z8fFavXk2/fv2888xmM/369WP58uUlrrN8+fJiywP079//lMuLiIiInAsC2ml88OBBXC4XsbGxxebHxsayefPmEtdJTU0tcfnU1NQSl3c6nTidx0ewz8wseTBKERERkaos4OfU+drEiROJjo72Tq1btw50SSIiIiIVLqChrlatWlgsFtLS0orNT0tLIy6u5PGC4uLiyrT82LFjSU9P904bN26smOJFREREKpGAhjqbzUbnzp1ZuHChd57b7WbhwoUkJiaWuE5iYmKx5QHmz59/yuXtdjtRUVHeKTIysuI+gIiIiEglEfCBWMaMGcOIESPo0qUL3bp1Y/LkyWRnZ3PzzZ4bgg8fPpw6deowcaLnfor33HMPvXv35oUXXuDyyy9nxowZrFq1ijfffDOQH0NEREQkoAIe6oYMGcKBAwcYN24cqampdOjQgblz53ovhkhOTsZsPt6g2KNHDz766CMeffRR/v3vf9OsWTNmz57Neef57hYdIiIiIpVdwMep8zeNUyciIiJVRZUZp05EREREKoZCnYiIiEgQUKgTERERCQIBv1DC39xuNwApKSkBrkRERETk9IrySlF+OZ1zLtQVDVzcrVu3AFciIiIiUjppaWnUr1//tMucc1e/FhYWsnbtWmJjY4sNlVLRMjMzad26NRs3btSAx5WEjknlpONS+eiYVE46LpWPP46J2+0mLS2Njh07EhJy+ra4cy7U+UtGRgbR0dGkp6cTFRUV6HIEHZPKSsel8tExqZx0XCqfynZMdKGEiIiISBBQqBMREREJAgp1PmK32xk/fjx2uz3QpcgxOiaVk45L5aNjUjnpuFQ+le2Y6Jw6ERERkSCgljoRERGRIKBQJyIiIhIEFOpEREREgoBC3Vl47bXXaNiwIQ6Hg+7du/Prr7+edvmZM2fSsmVLHA4Hbdu2Zc6cOX6q9NxRlmPy1ltvceGFF1K9enWqV69Ov379zngMpXzK+m+lyIwZMzCZTAwePNi3BZ6DynpMjh49yqhRo4iPj8dut9O8eXP9H1bBynpMJk+eTIsWLQgNDaVevXr861//Ii8vz0/Vnht++uknBg0aREJCAiaTidmzZ59xncWLF9OpUyfsdjtNmzZl+vTpPq/Ty5BymTFjhmGz2Yx3333X2LBhg3HbbbcZ1apVM9LS0kpcfunSpYbFYjGee+45Y+PGjcajjz5qWK1WY926dX6uPHiV9Zj87W9/M1577TVj7dq1xqZNm4ybbrrJiI6ONvbu3evnyoNbWY9LkZ07dxp16tQxLrzwQuOqq67yT7HniLIeE6fTaXTp0sW47LLLjJ9//tnYuXOnsXjxYiMpKcnPlQevsh6TDz/80LDb7caHH35o7Ny505g3b54RHx9v/Otf//Jz5cFtzpw5xiOPPGJ88cUXBmDMmjXrtMvv2LHDCAsLM8aMGWNs3LjRePXVVw2LxWLMnTvXL/Uq1JVTt27djFGjRnlfu1wuIyEhwZg4cWKJy99www3G5ZdfXmxe9+7djX/84x8+rfNcUtZj8leFhYVGZGSk8b///c9XJZ6TynNcCgsLjR49ehhvv/22MWLECIW6ClbWYzJ16lSjcePGRn5+vr9KPOeU9ZiMGjXKuPjii4vNGzNmjNGzZ0+f1nkuK02oe/DBB402bdoUmzdkyBCjf//+PqzsOHW/lkN+fj6rV6+mX79+3nlms5l+/fqxfPnyEtdZvnx5seUB+vfvf8rlpWzKc0z+Kicnh4KCAmrUqOGrMs855T0uTzzxBDExMYwcOdIfZZ5TynNMvvrqKxITExk1ahSxsbGcd955PPPMM7hcLn+VHdTKc0x69OjB6tWrvV20O3bsYM6cOVx22WV+qVlKFujf9ae/M6yU6ODBg7hcLmJjY4vNj42NZfPmzSWuk5qaWuLyqampPqvzXFKeY/JXDz30EAkJCSf9g5TyK89x+fnnn3nnnXdISkryQ4XnnvIckx07dvDDDz8wbNgw5syZw7Zt27jzzjspKChg/Pjx/ig7qJXnmPztb3/j4MGDXHDBBRiGQWFhIf/85z/597//7Y+S5RRO9bs+IyOD3NxcQkNDfbp/tdSJAM8++ywzZsxg1qxZOByOQJdzzsrMzOTGG2/krbfeolatWoEuR45xu93ExMTw5ptv0rlzZ4YMGcIjjzzC66+/HujSzlmLFy/mmWee4b///S9r1qzhiy++4Ntvv+XJJ58MdGkSQGqpK4datWphsVhIS0srNj8tLY24uLgS14mLiyvT8lI25TkmRSZNmsSzzz7LggULaNeunS/LPOeU9bhs376dXbt2MWjQIO88t9sNQEhICFu2bKFJkya+LTrIleffSnx8PFarFYvF4p3XqlUrUlNTyc/Px2az+bTmYFeeY/LYY49x4403cuuttwLQtm1bsrOzuf3223nkkUcwm9VmEwin+l0fFRXl81Y6UEtdudhsNjp37szChQu989xuNwsXLiQxMbHEdRITE4stDzB//vxTLi9lU55jAvDcc8/x5JNPMnfuXLp06eKPUs8pZT0uLVu2ZN26dSQlJXmnK6+8kosuuoikpCTq1avnz/KDUnn+rfTs2ZNt27Z5AzbAH3/8QXx8vAJdBSjPMcnJyTkpuBWFbkN3/wyYgP+u98vlGEFoxowZht1uN6ZPn25s3LjRuP32241q1aoZqamphmEYxo033mg8/PDD3uWXLl1qhISEGJMmTTI2bdpkjB8/XkOaVLCyHpNnn33WsNlsxmeffWakpKR4p8zMzEB9hKBU1uPyV7r6teKV9ZgkJycbkZGRxujRo40tW7YY33zzjRETE2M89dRTgfoIQaesx2T8+PFGZGSk8fHHHxs7duwwvv/+e6NJkybGDTfcEKiPEJQyMzONtWvXGmvXrjUA48UXXzTWrl1r7N692zAMw3j44YeNG2+80bt80ZAmDzzwgLFp0ybjtdde05AmVcWrr75q1K9f37DZbEa3bt2MFStWeN/r3bu3MWLEiGLLf/rpp0bz5s0Nm81mtGnTxvj222/9XHHwK8sxadCggQGcNI0fP97/hQe5sv5bOZFCnW+U9ZgsW7bM6N69u2G3243GjRsbTz/9tFFYWOjnqoNbWY5JQUGBMWHCBKNJkyaGw+Ew6tWrZ9x5553GkSNH/F94EFu0aFGJvyeKjsWIESOM3r17n7ROhw4dDJvNZjRu3NiYNm2a3+o1GYbaaUVERESqOp1TJyIiIhIEFOpEREREgoBCnYiIiEgQUKgTERERCQIKdSIiIiJBQKFOREREJAgo1ImIiIgEAYU6ERERkSCgUCci4mcmk4nZs2cHugwRCTIKdSJyTrnpppswmUwnTQMGDAh0aSIiZyUk0AWIiPjbgAEDmDZtWrF5drs9QNWIiFQMtdSJyDnHbrcTFxdXbKpevTrg6RqdOnUqAwcOJDQ0lMaNG/PZZ58VW3/dunVcfPHFhIaGUrNmTW6//XaysrKKLfPuu+/Spk0b7HY78fHxjB49utj7Bw8e5OqrryYsLIxmzZrx1Vdfed87cuQIw4YNo3bt2oSGhtKsWbOTQqiIyF8p1ImI/MVjjz3Gtddey2+//cawYcP4v//7PzZt2gRAdnY2/fv3p3r16qxcuZKZM2eyYMGCYqFt6tSpjBo1ittvv51169bx1Vdf0bRp02L7ePzxx7nhhhv4/fffueyyyxg2bBiHDx/27n/jxo189913bNq0ialTp1KrVi3/fQEiUjUZIiLnkBEjRhgWi8UIDw8vNj399NOGYRgGYPzzn/8stk737t2NO+64wzAMw3jzzTeN6tWrG1lZWd73v/32W8NsNhupqamGYRhGQkKC8cgjj5yyBsB49NFHva+zsrIMwPjuu+8MwzCMQYMGGTfffHPFfGAROWfonDoROedcdNFFTJ06tdi8GjVqeJ8nJiYWey8xMZGkpCQANm3aRPv27QkPD/e+37NnT9xuN1u2bMFkMrFv3z769u172hratWvnfR4eHk5UVBT79+8H4I477uDaa69lzZo1XHrppQwePJgePXqU67OKyLlDoU5Ezjnh4eEndYdWlNDQ0FItZ7Vai702mUy43W4ABg4cyO7du5kzZw7z58+nb9++jBo1ikmTJlV4vSISPHROnYjIX6xYseKk161atQKgVatW/Pbbb2RnZ3vfX7p0KWazmRYtWhAZGUnDhg1ZuHDhWdVQu3ZtRowYwQcffMDkyZN58803z2p7IhL81FInIuccp9NJampqsXkhISHeixFmzpxJly5duOCCC/jwww/59ddfeeeddwAYNmwY48ePZ8SIEUyYMIEDBw5w1113ceONNxIbGwvAhAkT+Oc//0lMTAwDBw4kMzOTpUuXctddd5WqvnHjxtG5c2fatGmD0+nkm2++8YZKEZFTUagTkXPO3LlziY+PLzavRYsWbN68GfBcmTpjxgzuvPNO4uPj+fjjj2ndujUAYWFhzJs3j3vuuYeuXbsSFhbGtddey4svvujd1ogRI8jLy+Oll17i/vvvp1atWlx33XWlrs9mszF27Fh27dpFaGgoF154ITNmzKiATy4iwcxkGIYR6CJERCoLk8nErFmzGDx4cKBLEREpE51TJyIiIhIEFOpEREREgoDOqRMROYHOSBGRqkotdSIiIiJBQKFOREREJAgo1ImIiIgEAYU6ERERkSCgUCciIiISBBTqRERERIKAQp2IiIhIEFCoExEREQkCCnUiIiIiQeD/AaUTUMo81btWAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"# 9. Save Fine-Tuned Model","metadata":{}},{"cell_type":"code","source":"import re\n\n\nfile_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\ntorch.save(model.state_dict(), file_name)\nprint(f\"Model saved as {file_name}\")\n\n# Load model via\n# model.load_state_dict(torch.load(\"gpt2-medium124M-sft.pth\"))","metadata":{"_uuid":"4a57b74c-eb5c-42cf-934a-443e4ca14374","_cell_guid":"903858f2-a743-4f19-9c25-bc19e5fb37be","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-10T14:17:01.095188Z","iopub.execute_input":"2025-12-10T14:17:01.095393Z","iopub.status.idle":"2025-12-10T14:17:02.072795Z","shell.execute_reply.started":"2025-12-10T14:17:01.095377Z","shell.execute_reply":"2025-12-10T14:17:02.072149Z"}},"outputs":[{"name":"stdout","text":"Model saved as gpt2-small124M-sft.pth\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# 10. Inference & Chat Interface","metadata":{}},{"cell_type":"code","source":"class ModelInference:\n    def __init__(self, model, tokenizer, device, base_config):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.device = device\n        self.context_length = base_config['context_length']\n        self.model.eval()\n    \n    def format_prompt(self, user_input):\n        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\nInstruction: {user_input}\nResponse: \"\"\"\n    \n    def generate(self, user_input, max_new_tokens=100, temperature=0.7, top_k=50):\n        formatted_prompt = self.format_prompt(user_input)\n        input_ids = self.tokenizer.encode(formatted_prompt)\n        input_tensor = torch.tensor(input_ids).unsqueeze(0).to(self.device)\n        \n        with torch.no_grad():\n            output_ids = generate(model=self.model, idx=input_tensor, max_new_tokens=max_new_tokens, context_size=self.context_length, temperature=temperature, top_k=top_k)\n        \n        response = self.tokenizer.decode(output_ids[0].tolist())\n        if \"Response:\" in response:\n            response = response.split(\"Response:\")[-1].strip()\n        return response\n    \n    def chat(self, max_new_tokens=100, temperature=0.7):\n        print(\"\\n\" + \"=\"*80 + \"\\n CHAT MODE | Type 'exit' to quit\\n\" + \"=\"*80 + \"\\n\")\n        while True:\n            user_input = input(\"You: \").strip()\n            if user_input.lower() in ['exit', 'quit']:\n                print(\"\\nGoodbye!\")\n                break\n            if not user_input:\n                continue\n            print(\"\\n Thinking...\", end='', flush=True)\n            response = self.generate(user_input, max_new_tokens, temperature)\n            print(\"\\r\" + \" \"*30 + \"\\r\", end='')\n            print(f\"Model: {response}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T14:17:02.073500Z","iopub.execute_input":"2025-12-10T14:17:02.073721Z","iopub.status.idle":"2025-12-10T14:17:02.081207Z","shell.execute_reply.started":"2025-12-10T14:17:02.073696Z","shell.execute_reply":"2025-12-10T14:17:02.080339Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"questions = [\n    \"I want to learn a new skill but I'm not sure where to start or if it's worth my time.\",\n    \"How should I handle a friend who keeps borrowing money and not paying me back?\",\n    \"I'm thinking about changing careers but I'm worried about starting over. Is it worth it?\",\n    \"How do I set healthy boundaries with family members who are very demanding?\",\n    \"Can you explain how machine learning models are actually trained?\",\n]\n\nfor q in questions:\n    print(\"You:\", q)\n    print(\"Model:\", inference.generate(q))\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T14:53:21.309038Z","iopub.execute_input":"2025-12-10T14:53:21.309330Z","iopub.status.idle":"2025-12-10T14:53:29.149845Z","shell.execute_reply.started":"2025-12-10T14:53:21.309308Z","shell.execute_reply":"2025-12-10T14:53:29.148954Z"}},"outputs":[{"name":"stdout","text":"You: I want to learn a new skill but I'm not sure where to start or if it's worth my time.\nModel: ~~ Instruction:\nLearning something new is always worth the investment in yourself. Start small: commit to just 15-30 minutes a day rather than overwhelming yourself. Find the best format for you—some people learn by doing, others by watching videos, others by reading. There are countless free resources available. Pick one skill, give it a real try for a month, and see if it sparks joy. If it does, keep going. If not, no harm done.<|endoftext|>The author builds tension\n\nYou: How should I handle a friend who keeps borrowing money and not paying me back?\nModel: This is a tough situation that requires direct but kind communication. You might say, 'I care about our friendship, but I can't keep lending money. Let's figure out what you actually need help with.' Set a clear boundary: you're not a bank, but you might help with budgeting, job searching, or other solutions. True friends will respect this. If they don't, that tells you something important about what they value.<|endoftext|>Stephen King excels at making ordinary people in\n\nYou: I'm thinking about changing careers but I'm worried about starting over. Is it worth it?\nModel: Career changes are scary because the familiar feels safe, but you're not starting from zero—you're bringing all your experience and skills with you. Consider doing some exploration first: talk to people in the field, maybe do a side project, take a course. The truth is that staying in a job that doesn't fulfill you has a cost too. Sometimes the leap is worth it.<|endoftext|>This is common and not a character flaw. Finishing books can feel like obligation rather than pleasure.\n\nYou: How do I set healthy boundaries with family members who are very demanding?\nModel: Healthy boundaries are acts of love, even though they might not feel that way at first. Be clear and kind: 'I love you and I'm here for you, but I can't be available every day' or 'I can help with X but not Y.' Stick to these boundaries consistently—that consistency is what makes them real. People who respect you will accept them. Those who don't are showing you important information.<|endoftext|>This character's motivation stems from [deep psychological need] combined\n\nYou: Can you explain how machine learning models are actually trained?\nModel: ------------\nGreat question for machine learning. At a high level, machine learning works like this: you give a model lots of examples with answers, and it learns patterns from that data. For instance, if you show it thousands of photos labeled 'cat' or 'dog,' it gradually learns what features make something a cat. The model adjusts its internal settings (called weights) by checking how wrong it was and improving. After enough iterations, it can recognize new, unseen photos. It's less about\n\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}